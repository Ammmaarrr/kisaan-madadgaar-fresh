{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a736bb49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "üîß CHECKING SYSTEM & INSTALLING DEPENDENCIES\n",
      "======================================================================\n",
      "Installing pillow...\n",
      "\n",
      "‚úÖ PyTorch version: 2.7.1+cu118\n",
      "üîß CUDA available: True\n",
      "üéÆ GPU: Quadro M1200\n",
      "üíæ GPU Memory: 4.3 GB\n",
      "üî¢ CUDA Version: 11.8\n",
      "\n",
      "üñ•Ô∏è Using device: cuda\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# CELL 1: Check GPU & Install Dependencies\n",
    "# ============================================\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"üîß CHECKING SYSTEM & INSTALLING DEPENDENCIES\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Install required packages\n",
    "packages = ['torch', 'torchvision', 'timm', 'tqdm', 'pillow', 'matplotlib', 'numpy', 'pandas']\n",
    "for pkg in packages:\n",
    "    try:\n",
    "        __import__(pkg.replace('-', '_'))\n",
    "    except ImportError:\n",
    "        print(f\"Installing {pkg}...\")\n",
    "        subprocess.check_call([sys.executable, '-m', 'pip', 'install', '-q', pkg])\n",
    "\n",
    "import torch\n",
    "print(f\"\\n‚úÖ PyTorch version: {torch.__version__}\")\n",
    "print(f\"üîß CUDA available: {torch.cuda.is_available()}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"üéÆ GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"üíæ GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "    print(f\"üî¢ CUDA Version: {torch.version.cuda}\")\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No GPU found - will use CPU (slower)\")\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "print(f\"\\nüñ•Ô∏è Using device: {device}\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a2746d92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö° Mixed Precision (AMP) enabled for faster training!\n",
      "\n",
      "‚úÖ All imports successful!\n",
      "üñ•Ô∏è Device: cuda\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# CELL 2: Import Libraries & Setup\n",
    "# ============================================\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import torchvision.transforms as transforms\n",
    "import timm\n",
    "\n",
    "# ‚ö° Speed optimizations\n",
    "if torch.cuda.is_available():\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    from torch.cuda.amp import GradScaler, autocast\n",
    "    scaler = GradScaler()\n",
    "    USE_AMP = True\n",
    "    print(\"‚ö° Mixed Precision (AMP) enabled for faster training!\")\n",
    "else:\n",
    "    USE_AMP = False\n",
    "    print(\"‚ö†Ô∏è AMP disabled (no GPU)\")\n",
    "\n",
    "print(f\"\\n‚úÖ All imports successful!\")\n",
    "print(f\"üñ•Ô∏è Device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d3d568d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "üìÇ LOADING LOCAL DATASET\n",
      "======================================================================\n",
      "üìÅ Data directory: D:\\kisaan madadgaar\\Plant-Disease-Detection\\data\\downloads\\PakistanCrops_Merged\n",
      "   Exists: True\n",
      "\n",
      "üìä Found 34 classes:\n",
      "   üìÇ Cotton___diseased_cotton_leaf: 2,842 images\n",
      "   üìÇ Cotton___diseased_cotton_plant: 7,362 images\n",
      "   üìÇ Cotton___fresh_cotton_leaf: 4,146 images\n",
      "   üìÇ Cotton___fresh_cotton_plant: 4,106 images\n",
      "   üìÇ Mango___Anthracnose: 3,994 images\n",
      "   üìÇ Mango___Bacterial_Canker: 3,994 images\n",
      "   üìÇ Mango___Cutting_Weevil: 3,994 images\n",
      "   üìÇ Mango___Die_Back: 3,994 images\n",
      "   üìÇ Mango___Gall_Midge: 3,994 images\n",
      "   üìÇ Mango___Healthy: 3,994 images\n",
      "   üìÇ Mango___Powdery_Mildew: 3,994 images\n",
      "   üìÇ Mango___Sooty_Mould: 3,994 images\n",
      "   üìÇ Plantvillage___Pepper__bell___Bacterial_spot: 15,946 images\n",
      "   üìÇ Plantvillage___Pepper__bell___healthy: 23,646 images\n",
      "   üìÇ Plantvillage___Potato___Early_blight: 15,994 images\n",
      "   üìÇ Plantvillage___Potato___healthy: 2,426 images\n",
      "   üìÇ Plantvillage___Potato___Late_blight: 15,994 images\n",
      "   üìÇ Plantvillage___Tomato__Target_Spot: 22,458 images\n",
      "   üìÇ Plantvillage___Tomato__Tomato_mosaic_virus: 5,962 images\n",
      "   üìÇ Plantvillage___Tomato__Tomato_YellowLeaf__Curl_Virus: 30,826 images\n",
      "   üìÇ Plantvillage___Tomato_Bacterial_spot: 26,502 images\n",
      "   üìÇ Plantvillage___Tomato_Early_blight: 15,994 images\n",
      "   üìÇ Plantvillage___Tomato_healthy: 24,358 images\n",
      "   üìÇ Plantvillage___Tomato_Late_blight: 25,634 images\n",
      "   üìÇ Plantvillage___Tomato_Leaf_Mold: 15,226 images\n",
      "   üìÇ Plantvillage___Tomato_Septoria_leaf_spot: 25,078 images\n",
      "   üìÇ Plantvillage___Tomato_Spider_mites_Two_spotted_spider_mite: 24,698 images\n",
      "   üìÇ Rice___BrownSpot: 8,362 images\n",
      "   üìÇ Rice___Healthy: 16,082 images\n",
      "   üìÇ Rice___Hispa: 8,698 images\n",
      "   üìÇ Rice___LeafBlast: 10,410 images\n",
      "   üìÇ Wheat___Healthy: 810 images\n",
      "   üìÇ Wheat___septoria: 770 images\n",
      "   üìÇ Wheat___stripe_rust: 1,658 images\n",
      "\n",
      "‚úÖ Total: 34 classes, 387,940 images\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# CELL 3: Load Dataset from Local Path\n",
    "# ============================================\n",
    "print(\"=\"*70)\n",
    "print(\"üìÇ LOADING LOCAL DATASET\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Dataset path - update this if your data is elsewhere\n",
    "DATA_DIR = Path(r\"D:\\kisaan madadgaar\\Plant-Disease-Detection\\data\\downloads\\PakistanCrops_Merged\")\n",
    "\n",
    "if not DATA_DIR.exists():\n",
    "    # Try alternate paths\n",
    "    alt_paths = [\n",
    "        Path(\"./data/downloads/PakistanCrops_Merged\"),\n",
    "        Path(\"../data/downloads/PakistanCrops_Merged\"),\n",
    "        Path(\"data/PakistanCrops_Merged\"),\n",
    "    ]\n",
    "    for alt in alt_paths:\n",
    "        if alt.exists():\n",
    "            DATA_DIR = alt\n",
    "            break\n",
    "\n",
    "print(f\"üìÅ Data directory: {DATA_DIR}\")\n",
    "print(f\"   Exists: {DATA_DIR.exists()}\")\n",
    "\n",
    "if not DATA_DIR.exists():\n",
    "    raise FileNotFoundError(f\"‚ùå Data not found at {DATA_DIR}\")\n",
    "\n",
    "# Count classes and images\n",
    "class_folders = [f for f in DATA_DIR.iterdir() if f.is_dir()]\n",
    "print(f\"\\nüìä Found {len(class_folders)} classes:\")\n",
    "\n",
    "all_classes = {}\n",
    "total_images = 0\n",
    "\n",
    "for folder in sorted(class_folders):\n",
    "    images = list(folder.glob('*.jpg')) + list(folder.glob('*.jpeg')) + list(folder.glob('*.png'))\n",
    "    images += list(folder.glob('*.JPG')) + list(folder.glob('*.JPEG')) + list(folder.glob('*.PNG'))\n",
    "    if len(images) > 0:\n",
    "        all_classes[folder.name] = [str(img) for img in images]\n",
    "        total_images += len(images)\n",
    "        print(f\"   üìÇ {folder.name}: {len(images):,} images\")\n",
    "\n",
    "print(f\"\\n‚úÖ Total: {len(all_classes)} classes, {total_images:,} images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "35c53254",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "üîß CREATING DATASET\n",
      "======================================================================\n",
      "‚úÖ Dataset created: 34 classes, 387,940 images\n",
      "\n",
      "üìã Classes:\n",
      "    1. Cotton___diseased_cotton_leaf: 2,842 images\n",
      "    2. Cotton___diseased_cotton_plant: 7,362 images\n",
      "    3. Cotton___fresh_cotton_leaf: 4,146 images\n",
      "    4. Cotton___fresh_cotton_plant: 4,106 images\n",
      "    5. Mango___Anthracnose: 3,994 images\n",
      "    6. Mango___Bacterial_Canker: 3,994 images\n",
      "    7. Mango___Cutting_Weevil: 3,994 images\n",
      "    8. Mango___Die_Back: 3,994 images\n",
      "    9. Mango___Gall_Midge: 3,994 images\n",
      "   10. Mango___Healthy: 3,994 images\n",
      "   11. Mango___Powdery_Mildew: 3,994 images\n",
      "   12. Mango___Sooty_Mould: 3,994 images\n",
      "   13. Plantvillage___Pepper__bell___Bacterial_spot: 15,946 images\n",
      "   14. Plantvillage___Pepper__bell___healthy: 23,646 images\n",
      "   15. Plantvillage___Potato___Early_blight: 15,994 images\n",
      "   16. Plantvillage___Potato___Late_blight: 15,994 images\n",
      "   17. Plantvillage___Potato___healthy: 2,426 images\n",
      "   18. Plantvillage___Tomato_Bacterial_spot: 26,502 images\n",
      "   19. Plantvillage___Tomato_Early_blight: 15,994 images\n",
      "   20. Plantvillage___Tomato_Late_blight: 25,634 images\n",
      "   21. Plantvillage___Tomato_Leaf_Mold: 15,226 images\n",
      "   22. Plantvillage___Tomato_Septoria_leaf_spot: 25,078 images\n",
      "   23. Plantvillage___Tomato_Spider_mites_Two_spotted_spider_mite: 24,698 images\n",
      "   24. Plantvillage___Tomato__Target_Spot: 22,458 images\n",
      "   25. Plantvillage___Tomato__Tomato_YellowLeaf__Curl_Virus: 30,826 images\n",
      "   26. Plantvillage___Tomato__Tomato_mosaic_virus: 5,962 images\n",
      "   27. Plantvillage___Tomato_healthy: 24,358 images\n",
      "   28. Rice___BrownSpot: 8,362 images\n",
      "   29. Rice___Healthy: 16,082 images\n",
      "   30. Rice___Hispa: 8,698 images\n",
      "   31. Rice___LeafBlast: 10,410 images\n",
      "   32. Wheat___Healthy: 810 images\n",
      "   33. Wheat___septoria: 770 images\n",
      "   34. Wheat___stripe_rust: 1,658 images\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# CELL 4: Create Dataset Class\n",
    "# ============================================\n",
    "print(\"=\"*70)\n",
    "print(\"üîß CREATING DATASET\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "class PlantDiseaseDataset(Dataset):\n",
    "    def __init__(self, image_paths, labels, transform=None):\n",
    "        self.image_paths = image_paths\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        try:\n",
    "            image = Image.open(self.image_paths[idx]).convert('RGB')\n",
    "            if self.transform:\n",
    "                image = self.transform(image)\n",
    "            return image, self.labels[idx]\n",
    "        except Exception as e:\n",
    "            # Return a black image if loading fails\n",
    "            print(f\"‚ö†Ô∏è Error loading {self.image_paths[idx]}: {e}\")\n",
    "            image = Image.new('RGB', (224, 224), (0, 0, 0))\n",
    "            if self.transform:\n",
    "                image = self.transform(image)\n",
    "            return image, self.labels[idx]\n",
    "\n",
    "# Build dataset\n",
    "all_image_paths = []\n",
    "all_labels = []\n",
    "class_names = []\n",
    "\n",
    "for idx, (class_name, paths) in enumerate(sorted(all_classes.items())):\n",
    "    class_names.append(class_name)\n",
    "    all_image_paths.extend(paths)\n",
    "    all_labels.extend([idx] * len(paths))\n",
    "\n",
    "num_classes = len(class_names)\n",
    "print(f\"‚úÖ Dataset created: {num_classes} classes, {len(all_image_paths):,} images\")\n",
    "\n",
    "# Show classes\n",
    "print(f\"\\nüìã Classes:\")\n",
    "for i, name in enumerate(class_names):\n",
    "    count = sum(1 for label in all_labels if label == i)\n",
    "    print(f\"   {i+1:2d}. {name}: {count:,} images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "01e73d84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "üìä CREATING DATA LOADERS\n",
      "======================================================================\n",
      "\n",
      "‚ö° Batch size: 16 (based on 4.3GB GPU memory)\n",
      "\n",
      "üìä Dataset Split:\n",
      "   Training:   271,558 images (16973 batches)\n",
      "   Validation: 58,191 images (1819 batches)\n",
      "   Test:       58,191 images (1819 batches)\n",
      "\n",
      "‚ö° Workers: 4, Pin Memory: True\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# CELL 5: Data Loaders\n",
    "# ============================================\n",
    "print(\"=\"*70)\n",
    "print(\"üìä CREATING DATA LOADERS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Transforms\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Create and split dataset\n",
    "full_dataset = PlantDiseaseDataset(all_image_paths, all_labels, train_transform)\n",
    "\n",
    "train_size = int(0.7 * len(full_dataset))\n",
    "val_size = int(0.15 * len(full_dataset))\n",
    "test_size = len(full_dataset) - train_size - val_size\n",
    "\n",
    "train_ds, val_ds, test_ds = random_split(\n",
    "    full_dataset, \n",
    "    [train_size, val_size, test_size],\n",
    "    generator=torch.Generator().manual_seed(42)\n",
    ")\n",
    "\n",
    "# Batch size - adjust based on your GPU memory\n",
    "# RTX 3060 (12GB): batch_size=32-64\n",
    "# RTX 3070/3080: batch_size=64-128\n",
    "# GTX 1650/1660: batch_size=16-32\n",
    "# CPU only: batch_size=8-16\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    gpu_mem = torch.cuda.get_device_properties(0).total_memory / 1e9\n",
    "    if gpu_mem >= 8:\n",
    "        batch_size = 32\n",
    "    elif gpu_mem >= 4:\n",
    "        batch_size = 16\n",
    "    else:\n",
    "        batch_size = 8\n",
    "else:\n",
    "    batch_size = 8\n",
    "\n",
    "print(f\"\\n‚ö° Batch size: {batch_size} (based on {gpu_mem:.1f}GB GPU memory)\" if torch.cuda.is_available() else f\"\\n‚ö° Batch size: {batch_size} (CPU mode)\")\n",
    "\n",
    "# Determine number of workers\n",
    "num_workers = min(4, os.cpu_count() or 1)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_ds, batch_size=batch_size, shuffle=True,\n",
    "    num_workers=num_workers, pin_memory=torch.cuda.is_available()\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_ds, batch_size=batch_size*2, shuffle=False,\n",
    "    num_workers=num_workers, pin_memory=torch.cuda.is_available()\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    test_ds, batch_size=batch_size*2, shuffle=False,\n",
    "    num_workers=num_workers, pin_memory=torch.cuda.is_available()\n",
    ")\n",
    "\n",
    "print(f\"\\nüìä Dataset Split:\")\n",
    "print(f\"   Training:   {len(train_ds):,} images ({len(train_loader)} batches)\")\n",
    "print(f\"   Validation: {len(val_ds):,} images ({len(val_loader)} batches)\")\n",
    "print(f\"   Test:       {len(test_ds):,} images ({len(test_loader)} batches)\")\n",
    "print(f\"\\n‚ö° Workers: {num_workers}, Pin Memory: {torch.cuda.is_available()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "58f9a56c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "üîÑ PREPARING DATA FOR 4GB GPU\n",
      "======================================================================\n",
      "‚úÖ Data: 38,779 images (10% sample)\n",
      "\n",
      "üìä Dataset Split:\n",
      "   Training:   27,145 images (3394 batches)\n",
      "   Validation: 5,816 images (727 batches)\n",
      "   Test:       5,818 images (728 batches)\n",
      "\n",
      "‚ö° Batch: 8, Workers: 0\n",
      "‚úÖ Ready for training!\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# üî¥ REDUCE DATA + SMALL BATCH (4GB GPU Fix)\n",
    "# ============================================\n",
    "import random\n",
    "import gc\n",
    "random.seed(42)\n",
    "\n",
    "# Clear GPU memory\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"üîÑ PREPARING DATA FOR 4GB GPU\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Sample 10% from each class\n",
    "sampled_paths = []\n",
    "sampled_labels = []\n",
    "\n",
    "for class_idx, class_name in enumerate(class_names):\n",
    "    class_indices = [i for i, l in enumerate(all_labels) if l == class_idx]\n",
    "    sample_size = max(30, int(len(class_indices) * 0.10))\n",
    "    sample_size = min(sample_size, len(class_indices))\n",
    "    sampled_indices = random.sample(class_indices, sample_size)\n",
    "    for i in sampled_indices:\n",
    "        sampled_paths.append(all_image_paths[i])\n",
    "        sampled_labels.append(all_labels[i])\n",
    "\n",
    "all_image_paths = sampled_paths\n",
    "all_labels = sampled_labels\n",
    "\n",
    "print(f\"‚úÖ Data: {len(all_image_paths):,} images (10% sample)\")\n",
    "\n",
    "# Recreate dataset\n",
    "full_dataset = PlantDiseaseDataset(all_image_paths, all_labels, train_transform)\n",
    "\n",
    "train_size = int(0.7 * len(full_dataset))\n",
    "val_size = int(0.15 * len(full_dataset))\n",
    "test_size = len(full_dataset) - train_size - val_size\n",
    "\n",
    "train_ds, val_ds, test_ds = random_split(\n",
    "    full_dataset, [train_size, val_size, test_size],\n",
    "    generator=torch.Generator().manual_seed(42)\n",
    ")\n",
    "\n",
    "# SMALL BATCH for 4GB GPU\n",
    "batch_size = 8  # Very small batch for 4GB GPU\n",
    "num_workers = 0  # Windows fix\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=num_workers, pin_memory=True)\n",
    "val_loader = DataLoader(val_ds, batch_size=batch_size, shuffle=False, num_workers=num_workers, pin_memory=True)\n",
    "test_loader = DataLoader(test_ds, batch_size=batch_size, shuffle=False, num_workers=num_workers, pin_memory=True)\n",
    "\n",
    "print(f\"\\nüìä Dataset Split:\")\n",
    "print(f\"   Training:   {len(train_ds):,} images ({len(train_loader)} batches)\")\n",
    "print(f\"   Validation: {len(val_ds):,} images ({len(val_loader)} batches)\")  \n",
    "print(f\"   Test:       {len(test_ds):,} images ({len(test_loader)} batches)\")\n",
    "print(f\"\\n‚ö° Batch: {batch_size}, Workers: {num_workers}\")\n",
    "print(\"‚úÖ Ready for training!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bd00ecd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "ü§ñ CREATING MODEL\n",
      "======================================================================\n",
      "\n",
      "ü§ñ Model: EfficientNet-B4\n",
      "üìä Classes: 34\n",
      "üî¢ Total Parameters: 17,609,578\n",
      "üî¢ Trainable Parameters: 17,609,578\n",
      "‚öôÔ∏è Optimizer: AdamW (lr=0.0001)\n",
      "üìÖ Scheduler: CosineAnnealingLR (10 epochs)\n",
      "üñ•Ô∏è Device: cuda\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# CELL 6: Create Model (EfficientNet-B4)\n",
    "# ============================================\n",
    "print(\"=\"*70)\n",
    "print(\"ü§ñ CREATING MODEL\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Create EfficientNet-B4 model\n",
    "model = timm.create_model('efficientnet_b4', pretrained=True, num_classes=num_classes)\n",
    "model = model.to(device)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=0.0001, weight_decay=0.01)\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=10, eta_min=1e-6)\n",
    "\n",
    "# Count parameters\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"\\nü§ñ Model: EfficientNet-B4\")\n",
    "print(f\"üìä Classes: {num_classes}\")\n",
    "print(f\"üî¢ Total Parameters: {total_params:,}\")\n",
    "print(f\"üî¢ Trainable Parameters: {trainable_params:,}\")\n",
    "print(f\"‚öôÔ∏è Optimizer: AdamW (lr=0.0001)\")\n",
    "print(f\"üìÖ Scheduler: CosineAnnealingLR (10 epochs)\")\n",
    "print(f\"üñ•Ô∏è Device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a94c1cd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "üöÄ STARTING TRAINING (10 Epochs)\n",
      "======================================================================\n",
      "üíæ Models will be saved to: D:\\kisaan madadgaar\\Plant-Disease-Detection\\saved_models\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3394/3394 [2:31:48<00:00,  2.68s/it, loss=2.7500, acc=80.7%]     \n",
      "Epoch 1/10 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 727/727 [11:27<00:00,  1.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   üíæ New best model saved! (Val Acc: 93.67%)\n",
      "\n",
      "üìä Epoch 1/10:\n",
      "   Train Loss: 0.6148 | Train Acc: 80.75%\n",
      "   Val Loss:   0.1746 | Val Acc:   93.67%\n",
      "   Best Val Acc: 93.67%\n",
      "   ‚è±Ô∏è Time: 9797s | ETA: 1469.6 min\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3394/3394 [2:15:04<00:00,  2.39s/it, loss=1.2539, acc=93.7%]  \n",
      "Epoch 2/10 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 727/727 [07:32<00:00,  1.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   üíæ New best model saved! (Val Acc: 96.29%)\n",
      "\n",
      "üìä Epoch 2/10:\n",
      "   Train Loss: 0.1775 | Train Acc: 93.72%\n",
      "   Val Loss:   0.1040 | Val Acc:   96.29%\n",
      "   Best Val Acc: 96.29%\n",
      "   ‚è±Ô∏è Time: 8558s | ETA: 1141.1 min\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3394/3394 [1:44:15<00:00,  1.84s/it, loss=0.7344, acc=95.6%]  \n",
      "Epoch 3/10 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 727/727 [04:36<00:00,  2.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Epoch 3/10:\n",
      "   Train Loss: 0.1198 | Train Acc: 95.63%\n",
      "   Val Loss:   0.1109 | Val Acc:   96.05%\n",
      "   Best Val Acc: 96.29%\n",
      "   ‚è±Ô∏è Time: 6532s | ETA: 762.1 min\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3394/3394 [2:09:36<00:00,  2.29s/it, loss=1.4395, acc=96.9%]  \n",
      "Epoch 4/10 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 727/727 [10:09<00:00,  1.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   üíæ New best model saved! (Val Acc: 96.72%)\n",
      "\n",
      "üìä Epoch 4/10:\n",
      "   Train Loss: 0.0883 | Train Acc: 96.88%\n",
      "   Val Loss:   0.0881 | Val Acc:   96.72%\n",
      "   Best Val Acc: 96.72%\n",
      "   ‚è±Ô∏è Time: 8387s | ETA: 838.7 min\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3394/3394 [2:15:05<00:00,  2.39s/it, loss=3.6719, acc=97.6%]  \n",
      "Epoch 5/10 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 727/727 [07:43<00:00,  1.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   üíæ New best model saved! (Val Acc: 96.75%)\n",
      "\n",
      "üìä Epoch 5/10:\n",
      "   Train Loss: 0.0675 | Train Acc: 97.62%\n",
      "   Val Loss:   0.1073 | Val Acc:   96.75%\n",
      "   Best Val Acc: 96.75%\n",
      "   ‚è±Ô∏è Time: 8570s | ETA: 714.2 min\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3394/3394 [2:04:19<00:00,  2.20s/it, loss=1.0557, acc=98.2%]  \n",
      "Epoch 6/10 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 727/727 [06:56<00:00,  1.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   üíæ New best model saved! (Val Acc: 97.82%)\n",
      "\n",
      "üìä Epoch 6/10:\n",
      "   Train Loss: 0.0533 | Train Acc: 98.15%\n",
      "   Val Loss:   0.0653 | Val Acc:   97.82%\n",
      "   Best Val Acc: 97.82%\n",
      "   ‚è±Ô∏è Time: 7876s | ETA: 525.1 min\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3394/3394 [2:05:43<00:00,  2.22s/it, loss=2.7871, acc=98.4%]  \n",
      "Epoch 7/10 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 727/727 [06:40<00:00,  1.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Epoch 7/10:\n",
      "   Train Loss: 0.0450 | Train Acc: 98.42%\n",
      "   Val Loss:   0.4069 | Val Acc:   94.24%\n",
      "   Best Val Acc: 97.82%\n",
      "   ‚è±Ô∏è Time: 7944s | ETA: 397.2 min\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3394/3394 [2:06:00<00:00,  2.23s/it, loss=0.2028, acc=98.7%]  \n",
      "Epoch 8/10 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 727/727 [06:33<00:00,  1.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Epoch 8/10:\n",
      "   Train Loss: 0.0355 | Train Acc: 98.74%\n",
      "   Val Loss:   0.1249 | Val Acc:   97.47%\n",
      "   Best Val Acc: 97.82%\n",
      "   ‚è±Ô∏è Time: 7954s | ETA: 265.1 min\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3394/3394 [3:18:31<00:00,  3.51s/it, loss=1.7500, acc=98.9%]      \n",
      "Epoch 9/10 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 727/727 [04:23<00:00,  2.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Epoch 9/10:\n",
      "   Train Loss: 0.0322 | Train Acc: 98.87%\n",
      "   Val Loss:   0.0686 | Val Acc:   97.80%\n",
      "   Best Val Acc: 97.82%\n",
      "   ‚è±Ô∏è Time: 12175s | ETA: 202.9 min\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10 [Train]:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1589/3394 [28:12<29:05,  1.03it/s, loss=0.0026, acc=99.0%]  "
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# CELL 7: Training Loop (10 Epochs)\n",
    "# ============================================\n",
    "import time\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"üöÄ STARTING TRAINING (10 Epochs)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "epochs = 10\n",
    "best_val_acc = 0.0\n",
    "history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': []}\n",
    "\n",
    "# Save directory\n",
    "SAVE_DIR = Path(r\"D:\\kisaan madadgaar\\Plant-Disease-Detection\\saved_models\")\n",
    "SAVE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "print(f\"üíæ Models will be saved to: {SAVE_DIR}\")\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # ============ Training Phase ============\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    train_correct = 0\n",
    "    train_total = 0\n",
    "    \n",
    "    pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs} [Train]\")\n",
    "    for images, labels in pbar:\n",
    "        images = images.to(device, non_blocking=True)\n",
    "        labels = labels.to(device, non_blocking=True)\n",
    "        \n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        \n",
    "        if USE_AMP:\n",
    "            with autocast():\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "        else:\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        train_total += labels.size(0)\n",
    "        train_correct += predicted.eq(labels).sum().item()\n",
    "        \n",
    "        pbar.set_postfix({\n",
    "            'loss': f'{loss.item():.4f}',\n",
    "            'acc': f'{100.*train_correct/train_total:.1f}%'\n",
    "        })\n",
    "    \n",
    "    train_acc = 100. * train_correct / train_total\n",
    "    train_loss = train_loss / len(train_loader)\n",
    "    \n",
    "    # ============ Validation Phase ============\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(val_loader, desc=f\"Epoch {epoch+1}/{epochs} [Val]\"):\n",
    "            images = images.to(device, non_blocking=True)\n",
    "            labels = labels.to(device, non_blocking=True)\n",
    "            \n",
    "            if USE_AMP:\n",
    "                with autocast():\n",
    "                    outputs = model(images)\n",
    "                    loss = criterion(outputs, labels)\n",
    "            else:\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "            \n",
    "            val_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            val_total += labels.size(0)\n",
    "            val_correct += predicted.eq(labels).sum().item()\n",
    "    \n",
    "    val_acc = 100. * val_correct / val_total\n",
    "    val_loss = val_loss / len(val_loader)\n",
    "    \n",
    "    # Save history\n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['train_acc'].append(train_acc)\n",
    "    history['val_loss'].append(val_loss)\n",
    "    history['val_acc'].append(val_acc)\n",
    "    \n",
    "    # Save best model\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        checkpoint = {\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'val_acc': val_acc,\n",
    "            'class_names': class_names,\n",
    "            'num_classes': num_classes,\n",
    "            'history': history\n",
    "        }\n",
    "        torch.save(checkpoint, SAVE_DIR / 'pakistan_model_best.pth')\n",
    "        print(f\"   üíæ New best model saved! (Val Acc: {val_acc:.2f}%)\")\n",
    "    \n",
    "    # Save class names\n",
    "    with open(SAVE_DIR / 'class_names.json', 'w') as f:\n",
    "        json.dump(class_names, f, indent=2)\n",
    "    \n",
    "    scheduler.step()\n",
    "    \n",
    "    elapsed = time.time() - start_time\n",
    "    eta = (epochs - epoch - 1) * elapsed / 60\n",
    "    \n",
    "    print(f\"\\nüìä Epoch {epoch+1}/{epochs}:\")\n",
    "    print(f\"   Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.2f}%\")\n",
    "    print(f\"   Val Loss:   {val_loss:.4f} | Val Acc:   {val_acc:.2f}%\")\n",
    "    print(f\"   Best Val Acc: {best_val_acc:.2f}%\")\n",
    "    print(f\"   ‚è±Ô∏è Time: {elapsed:.0f}s | ETA: {eta:.1f} min\")\n",
    "    print(\"-\"*70)\n",
    "\n",
    "print(f\"\\n\" + \"=\"*70)\n",
    "print(f\"‚úÖ TRAINING COMPLETE!\")\n",
    "print(f\"üèÜ Best Validation Accuracy: {best_val_acc:.2f}%\")\n",
    "print(f\"üíæ Model saved to: {SAVE_DIR / 'pakistan_model_best.pth'}\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96568c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# CELL 8: Test Evaluation\n",
    "# ============================================\n",
    "print(\"=\"*70)\n",
    "print(\"üß™ EVALUATING ON TEST SET\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Load best model\n",
    "checkpoint = torch.load(SAVE_DIR / 'pakistan_model_best.pth')\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.eval()\n",
    "\n",
    "test_correct = 0\n",
    "test_total = 0\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in tqdm(test_loader, desc=\"Testing\"):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        if USE_AMP:\n",
    "            with autocast():\n",
    "                outputs = model(images)\n",
    "        else:\n",
    "            outputs = model(images)\n",
    "        \n",
    "        _, predicted = outputs.max(1)\n",
    "        test_total += labels.size(0)\n",
    "        test_correct += predicted.eq(labels).sum().item()\n",
    "        \n",
    "        all_preds.extend(predicted.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "test_acc = 100. * test_correct / test_total\n",
    "\n",
    "print(f\"\\n\" + \"=\"*70)\n",
    "print(f\"üìä FINAL TEST RESULTS\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nüéØ Test Accuracy: {test_acc:.2f}%\")\n",
    "print(f\"‚úÖ Correct: {test_correct:,} / {test_total:,}\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2951b7c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# CELL 9: Plot Training History\n",
    "# ============================================\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "epochs_range = range(1, len(history['train_loss']) + 1)\n",
    "\n",
    "# Loss plot\n",
    "axes[0].plot(epochs_range, history['train_loss'], 'b-', label='Train Loss', linewidth=2, marker='o')\n",
    "axes[0].plot(epochs_range, history['val_loss'], 'r-', label='Val Loss', linewidth=2, marker='s')\n",
    "axes[0].set_xlabel('Epoch', fontsize=12)\n",
    "axes[0].set_ylabel('Loss', fontsize=12)\n",
    "axes[0].set_title('Training and Validation Loss', fontsize=14)\n",
    "axes[0].legend(fontsize=10)\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Accuracy plot\n",
    "axes[1].plot(epochs_range, history['train_acc'], 'b-', label='Train Accuracy', linewidth=2, marker='o')\n",
    "axes[1].plot(epochs_range, history['val_acc'], 'r-', label='Val Accuracy', linewidth=2, marker='s')\n",
    "axes[1].axhline(y=test_acc, color='g', linestyle='--', linewidth=2, label=f'Test Acc: {test_acc:.1f}%')\n",
    "axes[1].axhline(y=best_val_acc, color='orange', linestyle=':', linewidth=2, label=f'Best Val: {best_val_acc:.1f}%')\n",
    "axes[1].set_xlabel('Epoch', fontsize=12)\n",
    "axes[1].set_ylabel('Accuracy (%)', fontsize=12)\n",
    "axes[1].set_title('Training and Validation Accuracy', fontsize=14)\n",
    "axes[1].legend(fontsize=10)\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(SAVE_DIR / 'training_history.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\n‚úÖ Plot saved to: {SAVE_DIR / 'training_history.png'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7583e425",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# CELL 10: Save Final Model & Metadata\n",
    "# ============================================\n",
    "print(\"=\"*70)\n",
    "print(\"üíæ SAVING FINAL MODEL\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Save model info\n",
    "model_info = {\n",
    "    'class_names': class_names,\n",
    "    'num_classes': num_classes,\n",
    "    'test_accuracy': test_acc,\n",
    "    'best_val_accuracy': best_val_acc,\n",
    "    'model_architecture': 'efficientnet_b4',\n",
    "    'total_images': len(all_image_paths),\n",
    "    'epochs_trained': len(history['train_loss']),\n",
    "    'final_train_acc': history['train_acc'][-1],\n",
    "    'final_val_acc': history['val_acc'][-1],\n",
    "    'device': str(device)\n",
    "}\n",
    "\n",
    "with open(SAVE_DIR / 'model_info.json', 'w') as f:\n",
    "    json.dump(model_info, f, indent=2)\n",
    "\n",
    "with open(SAVE_DIR / 'training_history.json', 'w') as f:\n",
    "    json.dump(history, f, indent=2)\n",
    "\n",
    "# Copy to Flask app folder\n",
    "FLASK_DIR = Path(r\"D:\\kisaan madadgaar\\Plant-Disease-Detection\\Flask Deployed App\")\n",
    "if FLASK_DIR.exists():\n",
    "    import shutil\n",
    "    shutil.copy(SAVE_DIR / 'pakistan_model_best.pth', FLASK_DIR / 'pakistan_model_best.pth')\n",
    "    shutil.copy(SAVE_DIR / 'class_names.json', FLASK_DIR / 'class_names.json')\n",
    "    print(f\"\\nüìÅ Copied model files to Flask app folder!\")\n",
    "\n",
    "print(f\"\\nüíæ Files saved:\")\n",
    "print(f\"   ‚úÖ pakistan_model_best.pth (model weights)\")\n",
    "print(f\"   ‚úÖ class_names.json (class labels)\")\n",
    "print(f\"   ‚úÖ model_info.json (metadata)\")\n",
    "print(f\"   ‚úÖ training_history.json (training log)\")\n",
    "print(f\"   ‚úÖ training_history.png (plot)\")\n",
    "\n",
    "# File sizes\n",
    "model_size = (SAVE_DIR / 'pakistan_model_best.pth').stat().st_size / (1024*1024)\n",
    "print(f\"\\nüìä Model size: {model_size:.1f} MB\")\n",
    "\n",
    "print(f\"\\n\" + \"=\"*70)\n",
    "print(\"üéâ ALL DONE!\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nüìÅ Model saved to: {SAVE_DIR}\")\n",
    "print(f\"üéØ Test Accuracy: {test_acc:.2f}%\")\n",
    "print(f\"üèÜ Best Val Accuracy: {best_val_acc:.2f}%\")\n",
    "print(f\"\\nüöÄ Next: Run Flask app to test the model!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fb42e20",
   "metadata": {},
   "source": [
    "## ‚úÖ Training Complete!\n",
    "\n",
    "### üìÅ Saved Files:\n",
    "- `saved_models/pakistan_model_best.pth` - Model weights\n",
    "- `saved_models/class_names.json` - Class labels\n",
    "- `saved_models/model_info.json` - Metadata\n",
    "- `saved_models/training_history.png` - Training plot\n",
    "\n",
    "### üöÄ Next Steps:\n",
    "1. Model files automatically copied to `Flask Deployed App/` folder\n",
    "2. Run the Flask app: `python app.py`\n",
    "3. Test with images!\n",
    "\n",
    "### üáµüá∞ ⁄©ÿ≥ÿßŸÜ ŸÖÿØÿØ⁄Øÿßÿ± - Helping Pakistani Farmers with AI!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".conda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
