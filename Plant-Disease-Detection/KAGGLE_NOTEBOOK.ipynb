{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef6345ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# CELL 1: Check GPU and Datasets\n",
    "# ============================================\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"üîç CHECKING KAGGLE ENVIRONMENT\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Check GPU\n",
    "import torch\n",
    "print(f\"\\nüéÆ GPU Available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"   GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"   Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  NO GPU! Go to Settings ‚Üí Accelerator ‚Üí GPU\")\n",
    "\n",
    "# Check datasets\n",
    "print(\"\\nüì¶ Checking Datasets:\")\n",
    "kaggle_input = '/kaggle/input'\n",
    "if os.path.exists(kaggle_input):\n",
    "    datasets = os.listdir(kaggle_input)\n",
    "    for ds in datasets:\n",
    "        path = os.path.join(kaggle_input, ds)\n",
    "        count = sum([len(f) for _, _, f in os.walk(path)])\n",
    "        print(f\"  ‚úÖ {ds}: {count:,} files\")\n",
    "    print(f\"\\nüìä Total datasets: {len(datasets)}\")\n",
    "    if len(datasets) < 3:\n",
    "        print(\"\\n‚ö†Ô∏è  Add more datasets! Click '+ Add Data' on the right\")\n",
    "else:\n",
    "    print(\"‚ùå Not on Kaggle!\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a4e227a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# CELL 2: Install Packages & Setup\n",
    "# ============================================\n",
    "!pip install timm -q\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import torchvision.transforms as transforms\n",
    "import timm\n",
    "\n",
    "# ‚ö° Speed optimizations\n",
    "torch.backends.cudnn.benchmark = True\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "scaler = GradScaler()\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"‚úÖ Setup complete! Using: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "990dfd3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# CELL 3: Find and Load Datasets\n",
    "# ============================================\n",
    "def find_image_classes(base_path, max_depth=5):\n",
    "    \"\"\"Find all image class directories\"\"\"\n",
    "    image_extensions = {'.jpg', '.jpeg', '.png', '.JPG', '.JPEG', '.PNG'}\n",
    "    class_data = {}\n",
    "    \n",
    "    for root, dirs, files in os.walk(base_path):\n",
    "        depth = root[len(base_path):].count(os.sep)\n",
    "        if depth > max_depth:\n",
    "            continue\n",
    "            \n",
    "        image_files = [f for f in files if Path(f).suffix in image_extensions]\n",
    "        if image_files and len(image_files) > 50:\n",
    "            class_name = Path(root).name\n",
    "            if class_name not in class_data:\n",
    "                class_data[class_name] = []\n",
    "            class_data[class_name].extend([os.path.join(root, f) for f in image_files])\n",
    "    \n",
    "    return class_data\n",
    "\n",
    "# Auto-detect datasets\n",
    "all_classes = {}\n",
    "print(\"=\"*70)\n",
    "print(\"üìä ANALYZING DATASETS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "for dataset_name in os.listdir('/kaggle/input'):\n",
    "    path = f'/kaggle/input/{dataset_name}'\n",
    "    print(f\"\\nüîç Analyzing {dataset_name}...\")\n",
    "    classes = find_image_classes(path)\n",
    "    if classes:\n",
    "        # Determine crop type from dataset name\n",
    "        crop = 'other'\n",
    "        for c in ['rice', 'cotton', 'wheat', 'mango', 'plant', 'village']:\n",
    "            if c in dataset_name.lower():\n",
    "                crop = c if c not in ['plant', 'village'] else 'plantvillage'\n",
    "                break\n",
    "        all_classes[crop] = classes\n",
    "        print(f\"   Found: {len(classes)} classes, {sum(len(v) for v in classes.values()):,} images\")\n",
    "\n",
    "total_images = sum(len(imgs) for crop in all_classes.values() for imgs in crop.values())\n",
    "print(f\"\\nüìà TOTAL: {sum(len(c) for c in all_classes.values())} classes, {total_images:,} images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a072c184",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# CELL 4: Create Dataset Class\n",
    "# ============================================\n",
    "class PlantDiseaseDataset(Dataset):\n",
    "    def __init__(self, image_paths, labels, transform=None):\n",
    "        self.image_paths = image_paths\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image = Image.open(self.image_paths[idx]).convert('RGB')\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, self.labels[idx]\n",
    "\n",
    "# Build unified dataset\n",
    "all_image_paths = []\n",
    "all_labels = []\n",
    "class_names = []\n",
    "\n",
    "current_idx = 0\n",
    "for crop, classes in all_classes.items():\n",
    "    for class_name, paths in classes.items():\n",
    "        if len(paths) < 100:  # Skip tiny classes\n",
    "            continue\n",
    "        class_names.append(f\"{crop}___{class_name}\")\n",
    "        all_image_paths.extend(paths)\n",
    "        all_labels.extend([current_idx] * len(paths))\n",
    "        current_idx += 1\n",
    "\n",
    "num_classes = len(class_names)\n",
    "print(f\"‚úÖ Created dataset: {num_classes} classes, {len(all_image_paths):,} images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab4157ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# CELL 5: Data Loaders (Optimized)\n",
    "# ============================================\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Create and split\n",
    "full_dataset = PlantDiseaseDataset(all_image_paths, all_labels, train_transform)\n",
    "train_size = int(0.7 * len(full_dataset))\n",
    "val_size = int(0.15 * len(full_dataset))\n",
    "test_size = len(full_dataset) - train_size - val_size\n",
    "\n",
    "train_ds, val_ds, test_ds = random_split(full_dataset, [train_size, val_size, test_size],\n",
    "                                          generator=torch.Generator().manual_seed(42))\n",
    "\n",
    "# ‚ö° Optimized loaders\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, \n",
    "                          num_workers=4, pin_memory=True, prefetch_factor=2)\n",
    "val_loader = DataLoader(val_ds, batch_size=128, shuffle=False,\n",
    "                        num_workers=4, pin_memory=True)\n",
    "test_loader = DataLoader(test_ds, batch_size=128, shuffle=False,\n",
    "                         num_workers=4, pin_memory=True)\n",
    "\n",
    "print(f\"üìä Train: {len(train_ds):,} | Val: {len(val_ds):,} | Test: {len(test_ds):,}\")\n",
    "print(f\"‚ö° Batch: {batch_size} | Workers: 4 | Pin Memory: True\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7317c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# CELL 6: Create Model\n",
    "# ============================================\n",
    "model = timm.create_model('efficientnet_b4', pretrained=True, num_classes=num_classes)\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=0.0001, weight_decay=0.01)\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=30, eta_min=1e-6)\n",
    "\n",
    "print(f\"ü§ñ Model: EfficientNet-B4\")\n",
    "print(f\"üìä Classes: {num_classes}\")\n",
    "print(f\"‚öôÔ∏è  Optimizer: AdamW (lr=0.0001)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c5ed1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# CELL 7: Training Loop (‚ö° Mixed Precision)\n",
    "# ============================================\n",
    "import time\n",
    "\n",
    "epochs = 30  # Reduced for faster training\n",
    "best_val_acc = 0.0\n",
    "history = {'train_loss': [], 'val_acc': []}\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"üöÄ STARTING TRAINING (Mixed Precision + cuDNN)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    start = time.time()\n",
    "    \n",
    "    # Train\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for images, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\"):\n",
    "        images, labels = images.to(device, non_blocking=True), labels.to(device, non_blocking=True)\n",
    "        \n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        with autocast():\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "        \n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        train_loss += loss.item()\n",
    "    \n",
    "    # Validate\n",
    "    model.eval()\n",
    "    correct, total = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            with autocast():\n",
    "                outputs = model(images)\n",
    "            _, pred = outputs.max(1)\n",
    "            correct += pred.eq(labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "    \n",
    "    val_acc = 100. * correct / total\n",
    "    history['train_loss'].append(train_loss / len(train_loader))\n",
    "    history['val_acc'].append(val_acc)\n",
    "    \n",
    "    # Save best\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        torch.save({\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'class_names': class_names,\n",
    "            'num_classes': num_classes,\n",
    "            'val_acc': val_acc\n",
    "        }, 'pakistan_model_best.pth')\n",
    "    \n",
    "    scheduler.step()\n",
    "    elapsed = time.time() - start\n",
    "    eta = (epochs - epoch - 1) * elapsed / 60\n",
    "    \n",
    "    print(f\"  Loss: {train_loss/len(train_loader):.4f} | Val Acc: {val_acc:.2f}% | \"\n",
    "          f\"Best: {best_val_acc:.2f}% | Time: {elapsed:.0f}s | ETA: {eta:.1f}min\")\n",
    "\n",
    "print(f\"\\n‚úÖ Training complete! Best accuracy: {best_val_acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a06fd5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# CELL 8: Test Evaluation\n",
    "# ============================================\n",
    "checkpoint = torch.load('pakistan_model_best.pth')\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.eval()\n",
    "\n",
    "correct, total = 0, 0\n",
    "with torch.no_grad():\n",
    "    for images, labels in tqdm(test_loader, desc=\"Testing\"):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, pred = outputs.max(1)\n",
    "        correct += pred.eq(labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "test_acc = 100. * correct / total\n",
    "print(f\"\\nüéØ TEST ACCURACY: {test_acc:.2f}%\")\n",
    "print(f\"‚úÖ {correct:,} / {total:,} correct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0837f729",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# CELL 9: Save Final Model\n",
    "# ============================================\n",
    "# Save metadata\n",
    "model_info = {\n",
    "    'class_names': class_names,\n",
    "    'num_classes': num_classes,\n",
    "    'test_accuracy': test_acc,\n",
    "    'best_val_accuracy': best_val_acc,\n",
    "    'model_architecture': 'efficientnet_b4'\n",
    "}\n",
    "\n",
    "with open('class_names.json', 'w') as f:\n",
    "    json.dump(class_names, f, indent=2)\n",
    "\n",
    "with open('model_info.json', 'w') as f:\n",
    "    json.dump(model_info, f, indent=2)\n",
    "\n",
    "print(\"üíæ Files saved to /kaggle/working/:\")\n",
    "print(\"  ‚úì pakistan_model_best.pth\")\n",
    "print(\"  ‚úì class_names.json\")\n",
    "print(\"  ‚úì model_info.json\")\n",
    "print(\"\\nüì• Download from 'Output' tab on the right ‚Üí\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9936d000",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# CELL 10: Plot Training History\n",
    "# ============================================\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "ax1.plot(history['train_loss'])\n",
    "ax1.set_title('Training Loss')\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "ax2.plot(history['val_acc'])\n",
    "ax2.axhline(y=test_acc, color='r', linestyle='--', label=f'Test: {test_acc:.1f}%')\n",
    "ax2.set_title('Validation Accuracy')\n",
    "ax2.set_xlabel('Epoch')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('training_history.png', dpi=150)\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüéâ DONE! Download your model from the Output tab.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
