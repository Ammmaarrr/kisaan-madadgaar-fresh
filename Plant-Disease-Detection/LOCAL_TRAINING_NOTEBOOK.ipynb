{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a736bb49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "üîß CHECKING SYSTEM & INSTALLING DEPENDENCIES\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\kisaan madadgaar\\.conda\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing pillow...\n",
      "\n",
      "‚úÖ PyTorch version: 2.7.1+cu118\n",
      "üîß CUDA available: True\n",
      "üéÆ GPU: Quadro M1200\n",
      "üíæ GPU Memory: 4.3 GB\n",
      "üî¢ CUDA Version: 11.8\n",
      "\n",
      "üñ•Ô∏è Using device: cuda\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# CELL 1: Check GPU & Install Dependencies\n",
    "# ============================================\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"üîß CHECKING SYSTEM & INSTALLING DEPENDENCIES\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Install required packages\n",
    "packages = ['torch', 'torchvision', 'timm', 'tqdm', 'pillow', 'matplotlib', 'numpy', 'pandas']\n",
    "for pkg in packages:\n",
    "    try:\n",
    "        __import__(pkg.replace('-', '_'))\n",
    "    except ImportError:\n",
    "        print(f\"Installing {pkg}...\")\n",
    "        subprocess.check_call([sys.executable, '-m', 'pip', 'install', '-q', pkg])\n",
    "\n",
    "import torch\n",
    "print(f\"\\n‚úÖ PyTorch version: {torch.__version__}\")\n",
    "print(f\"üîß CUDA available: {torch.cuda.is_available()}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"üéÆ GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"üíæ GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "    print(f\"üî¢ CUDA Version: {torch.version.cuda}\")\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No GPU found - will use CPU (slower)\")\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "print(f\"\\nüñ•Ô∏è Using device: {device}\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a2746d92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö° Mixed Precision (AMP) enabled for faster training!\n",
      "\n",
      "‚úÖ All imports successful!\n",
      "üñ•Ô∏è Device: cuda\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# CELL 2: Import Libraries & Setup\n",
    "# ============================================\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import torchvision.transforms as transforms\n",
    "import timm\n",
    "\n",
    "# ‚ö° Speed optimizations\n",
    "if torch.cuda.is_available():\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    from torch.cuda.amp import GradScaler, autocast\n",
    "    scaler = GradScaler()\n",
    "    USE_AMP = True\n",
    "    print(\"‚ö° Mixed Precision (AMP) enabled for faster training!\")\n",
    "else:\n",
    "    USE_AMP = False\n",
    "    print(\"‚ö†Ô∏è AMP disabled (no GPU)\")\n",
    "\n",
    "print(f\"\\n‚úÖ All imports successful!\")\n",
    "print(f\"üñ•Ô∏è Device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d3d568d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "üìÇ LOADING LOCAL DATASET\n",
      "======================================================================\n",
      "üìÅ Data directory: D:\\kisaan madadgaar\\Plant-Disease-Detection\\data\\downloads\\PakistanCrops_Merged\n",
      "   Exists: True\n",
      "\n",
      "üìä Found 34 classes:\n",
      "   üìÇ Cotton___diseased_cotton_leaf: 2,842 images\n",
      "   üìÇ Cotton___diseased_cotton_plant: 7,362 images\n",
      "   üìÇ Cotton___fresh_cotton_leaf: 4,146 images\n",
      "   üìÇ Cotton___fresh_cotton_plant: 4,106 images\n",
      "   üìÇ Mango___Anthracnose: 3,994 images\n",
      "   üìÇ Mango___Bacterial_Canker: 3,994 images\n",
      "   üìÇ Mango___Cutting_Weevil: 3,994 images\n",
      "   üìÇ Mango___Die_Back: 3,994 images\n",
      "   üìÇ Mango___Gall_Midge: 3,994 images\n",
      "   üìÇ Mango___Healthy: 3,994 images\n",
      "   üìÇ Mango___Powdery_Mildew: 3,994 images\n",
      "   üìÇ Mango___Sooty_Mould: 3,994 images\n",
      "   üìÇ Plantvillage___Pepper__bell___Bacterial_spot: 15,946 images\n",
      "   üìÇ Plantvillage___Pepper__bell___healthy: 23,646 images\n",
      "   üìÇ Plantvillage___Potato___Early_blight: 15,994 images\n",
      "   üìÇ Plantvillage___Potato___healthy: 2,426 images\n",
      "   üìÇ Plantvillage___Potato___Late_blight: 15,994 images\n",
      "   üìÇ Plantvillage___Tomato__Target_Spot: 22,458 images\n",
      "   üìÇ Plantvillage___Tomato__Tomato_mosaic_virus: 5,962 images\n",
      "   üìÇ Plantvillage___Tomato__Tomato_YellowLeaf__Curl_Virus: 30,826 images\n",
      "   üìÇ Plantvillage___Tomato_Bacterial_spot: 26,502 images\n",
      "   üìÇ Plantvillage___Tomato_Early_blight: 15,994 images\n",
      "   üìÇ Plantvillage___Tomato_healthy: 24,358 images\n",
      "   üìÇ Plantvillage___Tomato_Late_blight: 25,634 images\n",
      "   üìÇ Plantvillage___Tomato_Leaf_Mold: 15,226 images\n",
      "   üìÇ Plantvillage___Tomato_Septoria_leaf_spot: 25,078 images\n",
      "   üìÇ Plantvillage___Tomato_Spider_mites_Two_spotted_spider_mite: 24,698 images\n",
      "   üìÇ Rice___BrownSpot: 8,362 images\n",
      "   üìÇ Rice___Healthy: 16,082 images\n",
      "   üìÇ Rice___Hispa: 8,698 images\n",
      "   üìÇ Rice___LeafBlast: 10,410 images\n",
      "   üìÇ Wheat___Healthy: 810 images\n",
      "   üìÇ Wheat___septoria: 770 images\n",
      "   üìÇ Wheat___stripe_rust: 1,658 images\n",
      "\n",
      "‚úÖ Total: 34 classes, 387,940 images\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# CELL 3: Load Dataset from Local Path\n",
    "# ============================================\n",
    "print(\"=\"*70)\n",
    "print(\"üìÇ LOADING LOCAL DATASET\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Dataset path - update this if your data is elsewhere\n",
    "DATA_DIR = Path(r\"D:\\kisaan madadgaar\\Plant-Disease-Detection\\data\\downloads\\PakistanCrops_Merged\")\n",
    "\n",
    "if not DATA_DIR.exists():\n",
    "    # Try alternate paths\n",
    "    alt_paths = [\n",
    "        Path(\"./data/downloads/PakistanCrops_Merged\"),\n",
    "        Path(\"../data/downloads/PakistanCrops_Merged\"),\n",
    "        Path(\"data/PakistanCrops_Merged\"),\n",
    "    ]\n",
    "    for alt in alt_paths:\n",
    "        if alt.exists():\n",
    "            DATA_DIR = alt\n",
    "            break\n",
    "\n",
    "print(f\"üìÅ Data directory: {DATA_DIR}\")\n",
    "print(f\"   Exists: {DATA_DIR.exists()}\")\n",
    "\n",
    "if not DATA_DIR.exists():\n",
    "    raise FileNotFoundError(f\"‚ùå Data not found at {DATA_DIR}\")\n",
    "\n",
    "# Count classes and images\n",
    "class_folders = [f for f in DATA_DIR.iterdir() if f.is_dir()]\n",
    "print(f\"\\nüìä Found {len(class_folders)} classes:\")\n",
    "\n",
    "all_classes = {}\n",
    "total_images = 0\n",
    "\n",
    "for folder in sorted(class_folders):\n",
    "    images = list(folder.glob('*.jpg')) + list(folder.glob('*.jpeg')) + list(folder.glob('*.png'))\n",
    "    images += list(folder.glob('*.JPG')) + list(folder.glob('*.JPEG')) + list(folder.glob('*.PNG'))\n",
    "    if len(images) > 0:\n",
    "        all_classes[folder.name] = [str(img) for img in images]\n",
    "        total_images += len(images)\n",
    "        print(f\"   üìÇ {folder.name}: {len(images):,} images\")\n",
    "\n",
    "print(f\"\\n‚úÖ Total: {len(all_classes)} classes, {total_images:,} images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "35c53254",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "üîß CREATING DATASET\n",
      "======================================================================\n",
      "‚úÖ Dataset created: 34 classes, 387,940 images\n",
      "\n",
      "üìã Classes:\n",
      "    1. Cotton___diseased_cotton_leaf: 2,842 images\n",
      "    2. Cotton___diseased_cotton_plant: 7,362 images\n",
      "    3. Cotton___fresh_cotton_leaf: 4,146 images\n",
      "    4. Cotton___fresh_cotton_plant: 4,106 images\n",
      "    5. Mango___Anthracnose: 3,994 images\n",
      "    6. Mango___Bacterial_Canker: 3,994 images\n",
      "    7. Mango___Cutting_Weevil: 3,994 images\n",
      "    8. Mango___Die_Back: 3,994 images\n",
      "    9. Mango___Gall_Midge: 3,994 images\n",
      "   10. Mango___Healthy: 3,994 images\n",
      "   11. Mango___Powdery_Mildew: 3,994 images\n",
      "   12. Mango___Sooty_Mould: 3,994 images\n",
      "   13. Plantvillage___Pepper__bell___Bacterial_spot: 15,946 images\n",
      "   14. Plantvillage___Pepper__bell___healthy: 23,646 images\n",
      "   15. Plantvillage___Potato___Early_blight: 15,994 images\n",
      "   16. Plantvillage___Potato___Late_blight: 15,994 images\n",
      "   17. Plantvillage___Potato___healthy: 2,426 images\n",
      "   18. Plantvillage___Tomato_Bacterial_spot: 26,502 images\n",
      "   19. Plantvillage___Tomato_Early_blight: 15,994 images\n",
      "   20. Plantvillage___Tomato_Late_blight: 25,634 images\n",
      "   21. Plantvillage___Tomato_Leaf_Mold: 15,226 images\n",
      "   22. Plantvillage___Tomato_Septoria_leaf_spot: 25,078 images\n",
      "   23. Plantvillage___Tomato_Spider_mites_Two_spotted_spider_mite: 24,698 images\n",
      "   24. Plantvillage___Tomato__Target_Spot: 22,458 images\n",
      "   25. Plantvillage___Tomato__Tomato_YellowLeaf__Curl_Virus: 30,826 images\n",
      "   26. Plantvillage___Tomato__Tomato_mosaic_virus: 5,962 images\n",
      "   27. Plantvillage___Tomato_healthy: 24,358 images\n",
      "   28. Rice___BrownSpot: 8,362 images\n",
      "   29. Rice___Healthy: 16,082 images\n",
      "   30. Rice___Hispa: 8,698 images\n",
      "   31. Rice___LeafBlast: 10,410 images\n",
      "   32. Wheat___Healthy: 810 images\n",
      "   33. Wheat___septoria: 770 images\n",
      "   34. Wheat___stripe_rust: 1,658 images\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# CELL 4: Create Dataset Class\n",
    "# ============================================\n",
    "print(\"=\"*70)\n",
    "print(\"üîß CREATING DATASET\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "class PlantDiseaseDataset(Dataset):\n",
    "    def __init__(self, image_paths, labels, transform=None):\n",
    "        self.image_paths = image_paths\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        try:\n",
    "            image = Image.open(self.image_paths[idx]).convert('RGB')\n",
    "            if self.transform:\n",
    "                image = self.transform(image)\n",
    "            return image, self.labels[idx]\n",
    "        except Exception as e:\n",
    "            # Return a black image if loading fails\n",
    "            print(f\"‚ö†Ô∏è Error loading {self.image_paths[idx]}: {e}\")\n",
    "            image = Image.new('RGB', (224, 224), (0, 0, 0))\n",
    "            if self.transform:\n",
    "                image = self.transform(image)\n",
    "            return image, self.labels[idx]\n",
    "\n",
    "# Build dataset\n",
    "all_image_paths = []\n",
    "all_labels = []\n",
    "class_names = []\n",
    "\n",
    "for idx, (class_name, paths) in enumerate(sorted(all_classes.items())):\n",
    "    class_names.append(class_name)\n",
    "    all_image_paths.extend(paths)\n",
    "    all_labels.extend([idx] * len(paths))\n",
    "\n",
    "num_classes = len(class_names)\n",
    "print(f\"‚úÖ Dataset created: {num_classes} classes, {len(all_image_paths):,} images\")\n",
    "\n",
    "# Show classes\n",
    "print(f\"\\nüìã Classes:\")\n",
    "for i, name in enumerate(class_names):\n",
    "    count = sum(1 for label in all_labels if label == i)\n",
    "    print(f\"   {i+1:2d}. {name}: {count:,} images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "01e73d84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "üìä CREATING DATA LOADERS\n",
      "======================================================================\n",
      "\n",
      "‚ö° Batch size: 16 (based on 4.3GB GPU memory)\n",
      "\n",
      "üìä Dataset Split:\n",
      "   Training:   271,558 images (16973 batches)\n",
      "   Validation: 58,191 images (1819 batches)\n",
      "   Test:       58,191 images (1819 batches)\n",
      "\n",
      "‚ö° Workers: 4, Pin Memory: True\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# CELL 5: Data Loaders\n",
    "# ============================================\n",
    "print(\"=\"*70)\n",
    "print(\"üìä CREATING DATA LOADERS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Transforms\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Create and split dataset\n",
    "full_dataset = PlantDiseaseDataset(all_image_paths, all_labels, train_transform)\n",
    "\n",
    "train_size = int(0.7 * len(full_dataset))\n",
    "val_size = int(0.15 * len(full_dataset))\n",
    "test_size = len(full_dataset) - train_size - val_size\n",
    "\n",
    "train_ds, val_ds, test_ds = random_split(\n",
    "    full_dataset, \n",
    "    [train_size, val_size, test_size],\n",
    "    generator=torch.Generator().manual_seed(42)\n",
    ")\n",
    "\n",
    "# Batch size - adjust based on your GPU memory\n",
    "# RTX 3060 (12GB): batch_size=32-64\n",
    "# RTX 3070/3080: batch_size=64-128\n",
    "# GTX 1650/1660: batch_size=16-32\n",
    "# CPU only: batch_size=8-16\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    gpu_mem = torch.cuda.get_device_properties(0).total_memory / 1e9\n",
    "    if gpu_mem >= 8:\n",
    "        batch_size = 32\n",
    "    elif gpu_mem >= 4:\n",
    "        batch_size = 16\n",
    "    else:\n",
    "        batch_size = 8\n",
    "else:\n",
    "    batch_size = 8\n",
    "\n",
    "print(f\"\\n‚ö° Batch size: {batch_size} (based on {gpu_mem:.1f}GB GPU memory)\" if torch.cuda.is_available() else f\"\\n‚ö° Batch size: {batch_size} (CPU mode)\")\n",
    "\n",
    "# Determine number of workers\n",
    "num_workers = min(4, os.cpu_count() or 1)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_ds, batch_size=batch_size, shuffle=True,\n",
    "    num_workers=num_workers, pin_memory=torch.cuda.is_available()\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_ds, batch_size=batch_size*2, shuffle=False,\n",
    "    num_workers=num_workers, pin_memory=torch.cuda.is_available()\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    test_ds, batch_size=batch_size*2, shuffle=False,\n",
    "    num_workers=num_workers, pin_memory=torch.cuda.is_available()\n",
    ")\n",
    "\n",
    "print(f\"\\nüìä Dataset Split:\")\n",
    "print(f\"   Training:   {len(train_ds):,} images ({len(train_loader)} batches)\")\n",
    "print(f\"   Validation: {len(val_ds):,} images ({len(val_loader)} batches)\")\n",
    "print(f\"   Test:       {len(test_ds):,} images ({len(test_loader)} batches)\")\n",
    "print(f\"\\n‚ö° Workers: {num_workers}, Pin Memory: {torch.cuda.is_available()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "58f9a56c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "üîÑ PREPARING DATA FOR 4GB GPU\n",
      "======================================================================\n",
      "‚úÖ Data: 38,779 images (10% sample)\n",
      "\n",
      "üìä Dataset Split:\n",
      "   Training:   27,145 images (3394 batches)\n",
      "   Validation: 5,816 images (727 batches)\n",
      "   Test:       5,818 images (728 batches)\n",
      "\n",
      "‚ö° Batch: 8, Workers: 0\n",
      "‚úÖ Ready for training!\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# üî¥ REDUCE DATA + SMALL BATCH (4GB GPU Fix)\n",
    "# ============================================\n",
    "import random\n",
    "import gc\n",
    "random.seed(42)\n",
    "\n",
    "# Clear GPU memory\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"üîÑ PREPARING DATA FOR 4GB GPU\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Sample 10% from each class\n",
    "sampled_paths = []\n",
    "sampled_labels = []\n",
    "\n",
    "for class_idx, class_name in enumerate(class_names):\n",
    "    class_indices = [i for i, l in enumerate(all_labels) if l == class_idx]\n",
    "    sample_size = max(30, int(len(class_indices) * 0.10))\n",
    "    sample_size = min(sample_size, len(class_indices))\n",
    "    sampled_indices = random.sample(class_indices, sample_size)\n",
    "    for i in sampled_indices:\n",
    "        sampled_paths.append(all_image_paths[i])\n",
    "        sampled_labels.append(all_labels[i])\n",
    "\n",
    "all_image_paths = sampled_paths\n",
    "all_labels = sampled_labels\n",
    "\n",
    "print(f\"‚úÖ Data: {len(all_image_paths):,} images (10% sample)\")\n",
    "\n",
    "# Recreate dataset\n",
    "full_dataset = PlantDiseaseDataset(all_image_paths, all_labels, train_transform)\n",
    "\n",
    "train_size = int(0.7 * len(full_dataset))\n",
    "val_size = int(0.15 * len(full_dataset))\n",
    "test_size = len(full_dataset) - train_size - val_size\n",
    "\n",
    "train_ds, val_ds, test_ds = random_split(\n",
    "    full_dataset, [train_size, val_size, test_size],\n",
    "    generator=torch.Generator().manual_seed(42)\n",
    ")\n",
    "\n",
    "# SMALL BATCH for 4GB GPU\n",
    "batch_size = 8  # Very small batch for 4GB GPU\n",
    "num_workers = 0  # Windows fix\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=num_workers, pin_memory=True)\n",
    "val_loader = DataLoader(val_ds, batch_size=batch_size, shuffle=False, num_workers=num_workers, pin_memory=True)\n",
    "test_loader = DataLoader(test_ds, batch_size=batch_size, shuffle=False, num_workers=num_workers, pin_memory=True)\n",
    "\n",
    "print(f\"\\nüìä Dataset Split:\")\n",
    "print(f\"   Training:   {len(train_ds):,} images ({len(train_loader)} batches)\")\n",
    "print(f\"   Validation: {len(val_ds):,} images ({len(val_loader)} batches)\")  \n",
    "print(f\"   Test:       {len(test_ds):,} images ({len(test_loader)} batches)\")\n",
    "print(f\"\\n‚ö° Batch: {batch_size}, Workers: {num_workers}\")\n",
    "print(\"‚úÖ Ready for training!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bd00ecd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "ü§ñ CREATING MODEL\n",
      "======================================================================\n",
      "\n",
      "ü§ñ Model: EfficientNet-B4\n",
      "üìä Classes: 34\n",
      "üî¢ Total Parameters: 17,609,578\n",
      "üî¢ Trainable Parameters: 17,609,578\n",
      "‚öôÔ∏è Optimizer: AdamW (lr=0.0001)\n",
      "üìÖ Scheduler: CosineAnnealingLR (10 epochs)\n",
      "üñ•Ô∏è Device: cuda\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# CELL 6: Create Model (EfficientNet-B4)\n",
    "# ============================================\n",
    "print(\"=\"*70)\n",
    "print(\"ü§ñ CREATING MODEL\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Create EfficientNet-B4 model\n",
    "model = timm.create_model('efficientnet_b4', pretrained=True, num_classes=num_classes)\n",
    "model = model.to(device)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=0.0001, weight_decay=0.01)\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=10, eta_min=1e-6)\n",
    "\n",
    "# Count parameters\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"\\nü§ñ Model: EfficientNet-B4\")\n",
    "print(f\"üìä Classes: {num_classes}\")\n",
    "print(f\"üî¢ Total Parameters: {total_params:,}\")\n",
    "print(f\"üî¢ Trainable Parameters: {trainable_params:,}\")\n",
    "print(f\"‚öôÔ∏è Optimizer: AdamW (lr=0.0001)\")\n",
    "print(f\"üìÖ Scheduler: CosineAnnealingLR (10 epochs)\")\n",
    "print(f\"üñ•Ô∏è Device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a94c1cd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "üöÄ STARTING TRAINING (10 Epochs)\n",
      "======================================================================\n",
      "üíæ Models will be saved to: D:\\kisaan madadgaar\\Plant-Disease-Detection\\saved_models\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3394/3394 [2:31:48<00:00,  2.68s/it, loss=2.7500, acc=80.7%]     \n",
      "Epoch 1/10 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 727/727 [11:27<00:00,  1.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   üíæ New best model saved! (Val Acc: 93.67%)\n",
      "\n",
      "üìä Epoch 1/10:\n",
      "   Train Loss: 0.6148 | Train Acc: 80.75%\n",
      "   Val Loss:   0.1746 | Val Acc:   93.67%\n",
      "   Best Val Acc: 93.67%\n",
      "   ‚è±Ô∏è Time: 9797s | ETA: 1469.6 min\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3394/3394 [2:15:04<00:00,  2.39s/it, loss=1.2539, acc=93.7%]  \n",
      "Epoch 2/10 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 727/727 [07:32<00:00,  1.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   üíæ New best model saved! (Val Acc: 96.29%)\n",
      "\n",
      "üìä Epoch 2/10:\n",
      "   Train Loss: 0.1775 | Train Acc: 93.72%\n",
      "   Val Loss:   0.1040 | Val Acc:   96.29%\n",
      "   Best Val Acc: 96.29%\n",
      "   ‚è±Ô∏è Time: 8558s | ETA: 1141.1 min\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3394/3394 [1:44:15<00:00,  1.84s/it, loss=0.7344, acc=95.6%]  \n",
      "Epoch 3/10 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 727/727 [04:36<00:00,  2.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Epoch 3/10:\n",
      "   Train Loss: 0.1198 | Train Acc: 95.63%\n",
      "   Val Loss:   0.1109 | Val Acc:   96.05%\n",
      "   Best Val Acc: 96.29%\n",
      "   ‚è±Ô∏è Time: 6532s | ETA: 762.1 min\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3394/3394 [2:09:36<00:00,  2.29s/it, loss=1.4395, acc=96.9%]  \n",
      "Epoch 4/10 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 727/727 [10:09<00:00,  1.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   üíæ New best model saved! (Val Acc: 96.72%)\n",
      "\n",
      "üìä Epoch 4/10:\n",
      "   Train Loss: 0.0883 | Train Acc: 96.88%\n",
      "   Val Loss:   0.0881 | Val Acc:   96.72%\n",
      "   Best Val Acc: 96.72%\n",
      "   ‚è±Ô∏è Time: 8387s | ETA: 838.7 min\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3394/3394 [2:15:05<00:00,  2.39s/it, loss=3.6719, acc=97.6%]  \n",
      "Epoch 5/10 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 727/727 [07:43<00:00,  1.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   üíæ New best model saved! (Val Acc: 96.75%)\n",
      "\n",
      "üìä Epoch 5/10:\n",
      "   Train Loss: 0.0675 | Train Acc: 97.62%\n",
      "   Val Loss:   0.1073 | Val Acc:   96.75%\n",
      "   Best Val Acc: 96.75%\n",
      "   ‚è±Ô∏è Time: 8570s | ETA: 714.2 min\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3394/3394 [2:04:19<00:00,  2.20s/it, loss=1.0557, acc=98.2%]  \n",
      "Epoch 6/10 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 727/727 [06:56<00:00,  1.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   üíæ New best model saved! (Val Acc: 97.82%)\n",
      "\n",
      "üìä Epoch 6/10:\n",
      "   Train Loss: 0.0533 | Train Acc: 98.15%\n",
      "   Val Loss:   0.0653 | Val Acc:   97.82%\n",
      "   Best Val Acc: 97.82%\n",
      "   ‚è±Ô∏è Time: 7876s | ETA: 525.1 min\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3394/3394 [2:05:43<00:00,  2.22s/it, loss=2.7871, acc=98.4%]  \n",
      "Epoch 7/10 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 727/727 [06:40<00:00,  1.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Epoch 7/10:\n",
      "   Train Loss: 0.0450 | Train Acc: 98.42%\n",
      "   Val Loss:   0.4069 | Val Acc:   94.24%\n",
      "   Best Val Acc: 97.82%\n",
      "   ‚è±Ô∏è Time: 7944s | ETA: 397.2 min\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3394/3394 [2:06:00<00:00,  2.23s/it, loss=0.2028, acc=98.7%]  \n",
      "Epoch 8/10 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 727/727 [06:33<00:00,  1.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Epoch 8/10:\n",
      "   Train Loss: 0.0355 | Train Acc: 98.74%\n",
      "   Val Loss:   0.1249 | Val Acc:   97.47%\n",
      "   Best Val Acc: 97.82%\n",
      "   ‚è±Ô∏è Time: 7954s | ETA: 265.1 min\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3394/3394 [3:18:31<00:00,  3.51s/it, loss=1.7500, acc=98.9%]      \n",
      "Epoch 9/10 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 727/727 [04:23<00:00,  2.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Epoch 9/10:\n",
      "   Train Loss: 0.0322 | Train Acc: 98.87%\n",
      "   Val Loss:   0.0686 | Val Acc:   97.80%\n",
      "   Best Val Acc: 97.82%\n",
      "   ‚è±Ô∏è Time: 12175s | ETA: 202.9 min\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10 [Train]:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1589/3394 [28:12<29:05,  1.03it/s, loss=0.0026, acc=99.0%]  "
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# CELL 7: Training Loop (10 Epochs)\n",
    "# ============================================\n",
    "import time\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"üöÄ STARTING TRAINING (10 Epochs)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "epochs = 10\n",
    "best_val_acc = 0.0\n",
    "history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': []}\n",
    "\n",
    "# Save directory\n",
    "SAVE_DIR = Path(r\"D:\\kisaan madadgaar\\Plant-Disease-Detection\\saved_models\")\n",
    "SAVE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "print(f\"üíæ Models will be saved to: {SAVE_DIR}\")\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # ============ Training Phase ============\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    train_correct = 0\n",
    "    train_total = 0\n",
    "    \n",
    "    pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs} [Train]\")\n",
    "    for images, labels in pbar:\n",
    "        images = images.to(device, non_blocking=True)\n",
    "        labels = labels.to(device, non_blocking=True)\n",
    "        \n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        \n",
    "        if USE_AMP:\n",
    "            with autocast():\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "        else:\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        train_total += labels.size(0)\n",
    "        train_correct += predicted.eq(labels).sum().item()\n",
    "        \n",
    "        pbar.set_postfix({\n",
    "            'loss': f'{loss.item():.4f}',\n",
    "            'acc': f'{100.*train_correct/train_total:.1f}%'\n",
    "        })\n",
    "    \n",
    "    train_acc = 100. * train_correct / train_total\n",
    "    train_loss = train_loss / len(train_loader)\n",
    "    \n",
    "    # ============ Validation Phase ============\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(val_loader, desc=f\"Epoch {epoch+1}/{epochs} [Val]\"):\n",
    "            images = images.to(device, non_blocking=True)\n",
    "            labels = labels.to(device, non_blocking=True)\n",
    "            \n",
    "            if USE_AMP:\n",
    "                with autocast():\n",
    "                    outputs = model(images)\n",
    "                    loss = criterion(outputs, labels)\n",
    "            else:\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "            \n",
    "            val_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            val_total += labels.size(0)\n",
    "            val_correct += predicted.eq(labels).sum().item()\n",
    "    \n",
    "    val_acc = 100. * val_correct / val_total\n",
    "    val_loss = val_loss / len(val_loader)\n",
    "    \n",
    "    # Save history\n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['train_acc'].append(train_acc)\n",
    "    history['val_loss'].append(val_loss)\n",
    "    history['val_acc'].append(val_acc)\n",
    "    \n",
    "    # Save best model\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        checkpoint = {\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'val_acc': val_acc,\n",
    "            'class_names': class_names,\n",
    "            'num_classes': num_classes,\n",
    "            'history': history\n",
    "        }\n",
    "        torch.save(checkpoint, SAVE_DIR / 'pakistan_model_best.pth')\n",
    "        print(f\"   üíæ New best model saved! (Val Acc: {val_acc:.2f}%)\")\n",
    "    \n",
    "    # Save class names\n",
    "    with open(SAVE_DIR / 'class_names.json', 'w') as f:\n",
    "        json.dump(class_names, f, indent=2)\n",
    "    \n",
    "    scheduler.step()\n",
    "    \n",
    "    elapsed = time.time() - start_time\n",
    "    eta = (epochs - epoch - 1) * elapsed / 60\n",
    "    \n",
    "    print(f\"\\nüìä Epoch {epoch+1}/{epochs}:\")\n",
    "    print(f\"   Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.2f}%\")\n",
    "    print(f\"   Val Loss:   {val_loss:.4f} | Val Acc:   {val_acc:.2f}%\")\n",
    "    print(f\"   Best Val Acc: {best_val_acc:.2f}%\")\n",
    "    print(f\"   ‚è±Ô∏è Time: {elapsed:.0f}s | ETA: {eta:.1f} min\")\n",
    "    print(\"-\"*70)\n",
    "\n",
    "print(f\"\\n\" + \"=\"*70)\n",
    "print(f\"‚úÖ TRAINING COMPLETE!\")\n",
    "print(f\"üèÜ Best Validation Accuracy: {best_val_acc:.2f}%\")\n",
    "print(f\"üíæ Model saved to: {SAVE_DIR / 'pakistan_model_best.pth'}\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96568c78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "üß™ EVALUATING ON TEST SET\n",
      "======================================================================\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m=\u001b[39m\u001b[33m\"\u001b[39m*\u001b[32m70\u001b[39m)\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# Load best model\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m checkpoint = \u001b[43mtorch\u001b[49m.load(SAVE_DIR / \u001b[33m'\u001b[39m\u001b[33mpakistan_model_best.pth\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     10\u001b[39m model.load_state_dict(checkpoint[\u001b[33m'\u001b[39m\u001b[33mmodel_state_dict\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m     11\u001b[39m model.eval()\n",
      "\u001b[31mNameError\u001b[39m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# CELL 8: Test Evaluation\n",
    "# ============================================\n",
    "print(\"=\"*70)\n",
    "print(\"üß™ EVALUATING ON TEST SET\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Load best model\n",
    "checkpoint = torch.load(SAVE_DIR / 'pakistan_model_best.pth')\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.eval()\n",
    "\n",
    "test_correct = 0\n",
    "test_total = 0\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in tqdm(test_loader, desc=\"Testing\"):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        if USE_AMP:\n",
    "            with autocast():\n",
    "                outputs = model(images)\n",
    "        else:\n",
    "            outputs = model(images)\n",
    "        \n",
    "        _, predicted = outputs.max(1)\n",
    "        test_total += labels.size(0)\n",
    "        test_correct += predicted.eq(labels).sum().item()\n",
    "        \n",
    "        all_preds.extend(predicted.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "test_acc = 100. * test_correct / test_total\n",
    "\n",
    "print(f\"\\n\" + \"=\"*70)\n",
    "print(f\"üìä FINAL TEST RESULTS\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nüéØ Test Accuracy: {test_acc:.2f}%\")\n",
    "print(f\"‚úÖ Correct: {test_correct:,} / {test_total:,}\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f68bfcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Model file found!\n",
      "\n",
      "üìä LOCAL TRAINING RESULTS:\n",
      "==================================================\n",
      "üèÜ Best Val Accuracy: 97.82%\n",
      "üìä Classes: 34\n",
      "üìà Epochs: 6\n",
      "\n",
      "üìã Class Names:\n",
      "   1. Cotton___diseased_cotton_leaf\n",
      "   2. Cotton___diseased_cotton_plant\n",
      "   3. Cotton___fresh_cotton_leaf\n",
      "   4. Cotton___fresh_cotton_plant\n",
      "   5. Mango___Anthracnose\n",
      "   6. Mango___Bacterial_Canker\n",
      "   7. Mango___Cutting_Weevil\n",
      "   8. Mango___Die_Back\n",
      "   9. Mango___Gall_Midge\n",
      "   10. Mango___Healthy\n",
      "   11. Mango___Powdery_Mildew\n",
      "   12. Mango___Sooty_Mould\n",
      "   13. Plantvillage___Pepper__bell___Bacterial_spot\n",
      "   14. Plantvillage___Pepper__bell___healthy\n",
      "   15. Plantvillage___Potato___Early_blight\n",
      "   16. Plantvillage___Potato___Late_blight\n",
      "   17. Plantvillage___Potato___healthy\n",
      "   18. Plantvillage___Tomato_Bacterial_spot\n",
      "   19. Plantvillage___Tomato_Early_blight\n",
      "   20. Plantvillage___Tomato_Late_blight\n",
      "   21. Plantvillage___Tomato_Leaf_Mold\n",
      "   22. Plantvillage___Tomato_Septoria_leaf_spot\n",
      "   23. Plantvillage___Tomato_Spider_mites_Two_spotted_spider_mite\n",
      "   24. Plantvillage___Tomato__Target_Spot\n",
      "   25. Plantvillage___Tomato__Tomato_YellowLeaf__Curl_Virus\n",
      "   26. Plantvillage___Tomato__Tomato_mosaic_virus\n",
      "   27. Plantvillage___Tomato_healthy\n",
      "   28. Rice___BrownSpot\n",
      "   29. Rice___Healthy\n",
      "   30. Rice___Hispa\n",
      "   31. Rice___LeafBlast\n",
      "   32. Wheat___Healthy\n",
      "   33. Wheat___septoria\n",
      "   34. Wheat___stripe_rust\n",
      "==================================================\n",
      "\n",
      "üìà Final Train Acc: 98.15%\n",
      "üìà Final Val Acc: 97.82%\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# QUICK TEST - Load saved model and check\n",
    "# ============================================\n",
    "import json\n",
    "from pathlib import Path\n",
    "import torch\n",
    "\n",
    "SAVE_DIR = Path(r\"D:\\kisaan madadgaar\\Plant-Disease-Detection\\saved_models\")\n",
    "\n",
    "# Check if model exists\n",
    "if (SAVE_DIR / 'pakistan_model_best.pth').exists():\n",
    "    print(\"‚úÖ Model file found!\")\n",
    "    \n",
    "    # Load checkpoint\n",
    "    checkpoint = torch.load(SAVE_DIR / 'pakistan_model_best.pth', map_location='cpu')\n",
    "    \n",
    "    print(f\"\\nüìä LOCAL TRAINING RESULTS:\")\n",
    "    print(\"=\"*50)\n",
    "    print(f\"üèÜ Best Val Accuracy: {checkpoint['val_acc']:.2f}%\")\n",
    "    print(f\"üìä Classes: {checkpoint['num_classes']}\")\n",
    "    print(f\"üìà Epochs: {checkpoint['epoch'] + 1}\")\n",
    "    print(f\"\\nüìã Class Names:\")\n",
    "    for i, name in enumerate(checkpoint['class_names']):\n",
    "        print(f\"   {i+1}. {name}\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # Training history\n",
    "    if 'history' in checkpoint:\n",
    "        h = checkpoint['history']\n",
    "        print(f\"\\nüìà Final Train Acc: {h['train_acc'][-1]:.2f}%\")\n",
    "        print(f\"üìà Final Val Acc: {h['val_acc'][-1]:.2f}%\")\n",
    "else:\n",
    "    print(\"‚ùå Model not found - run training first!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2b2a7a62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "üî• ENSEMBLE MODEL SETUP\n",
      "======================================================================\n",
      "üñ•Ô∏è Device: cuda\n",
      "\n",
      "üìÅ Model Files:\n",
      "   Local Model: ‚úÖ Found\n",
      "   Colab Model: ‚úÖ Found\n",
      "\n",
      "üîÑ Loading Local Model (34 classes)...\n",
      "   ‚úÖ Local Model: 34 classes\n",
      "\n",
      "üîÑ Loading Colab Model (38 classes)...\n",
      "   ‚úÖ Colab Model: 38 classes\n",
      "\n",
      "======================================================================\n",
      "‚úÖ BOTH MODELS LOADED!\n",
      "======================================================================\n",
      "\n",
      "üìä Local Model Classes (34):\n",
      "   1. Cotton___diseased_cotton_leaf\n",
      "   2. Cotton___diseased_cotton_plant\n",
      "   3. Cotton___fresh_cotton_leaf\n",
      "   4. Cotton___fresh_cotton_plant\n",
      "   5. Mango___Anthracnose\n",
      "   6. Mango___Bacterial_Canker\n",
      "   7. Mango___Cutting_Weevil\n",
      "   8. Mango___Die_Back\n",
      "   9. Mango___Gall_Midge\n",
      "   10. Mango___Healthy\n",
      "   ...\n",
      "\n",
      "üìä Colab Model Classes (38):\n",
      "   1. Apple___Apple_scab\n",
      "   2. Apple___Black_rot\n",
      "   3. Apple___Cedar_apple_rust\n",
      "   4. Apple___healthy\n",
      "   5. Blueberry___healthy\n",
      "   6. Cherry_(including_sour)___Powdery_mildew\n",
      "   7. Cherry_(including_sour)___healthy\n",
      "   8. Corn_(maize)___Cercospora_leaf_spot Gray_leaf_spot\n",
      "   9. Corn_(maize)___Common_rust_\n",
      "   10. Corn_(maize)___Northern_Leaf_Blight\n",
      "   ...\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# üî• ENSEMBLE MODEL - Random Forest on Both Models\n",
    "# ============================================\n",
    "import torch\n",
    "import timm\n",
    "import json\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "from tqdm import tqdm\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"üî• ENSEMBLE MODEL SETUP\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"üñ•Ô∏è Device: {device}\")\n",
    "\n",
    "# Paths\n",
    "LOCAL_MODEL_PATH = Path(r\"D:\\kisaan madadgaar\\Plant-Disease-Detection\\saved_models\\pakistan_model_best.pth\")\n",
    "COLAB_MODEL_PATH = Path(r\"D:\\kisaan madadgaar\\Plant-Disease-Detection\\Flask Deployed App\\pakistan_model_best.pth\")\n",
    "\n",
    "# Check which models exist\n",
    "print(f\"\\nüìÅ Model Files:\")\n",
    "print(f\"   Local Model: {'‚úÖ Found' if LOCAL_MODEL_PATH.exists() else '‚ùå Not Found'}\")\n",
    "print(f\"   Colab Model: {'‚úÖ Found' if COLAB_MODEL_PATH.exists() else '‚ùå Not Found'}\")\n",
    "\n",
    "# Load Local Model (34 classes - Pakistani crops)\n",
    "print(\"\\nüîÑ Loading Local Model (34 classes)...\")\n",
    "local_checkpoint = torch.load(LOCAL_MODEL_PATH, map_location=device)\n",
    "local_classes = local_checkpoint['class_names']\n",
    "local_num_classes = local_checkpoint['num_classes']\n",
    "\n",
    "local_model = timm.create_model('efficientnet_b4', pretrained=False, num_classes=local_num_classes)\n",
    "local_model.load_state_dict(local_checkpoint['model_state_dict'])\n",
    "local_model = local_model.to(device)\n",
    "local_model.eval()\n",
    "print(f\"   ‚úÖ Local Model: {local_num_classes} classes\")\n",
    "\n",
    "# Load Colab Model (38 classes - PlantVillage)\n",
    "print(\"\\nüîÑ Loading Colab Model (38 classes)...\")\n",
    "colab_checkpoint = torch.load(COLAB_MODEL_PATH, map_location=device)\n",
    "colab_classes = colab_checkpoint['class_names'] if 'class_names' in colab_checkpoint else None\n",
    "\n",
    "# Try loading class names from JSON\n",
    "if colab_classes is None:\n",
    "    colab_json = Path(r\"D:\\kisaan madadgaar\\Plant-Disease-Detection\\Flask Deployed App\\class_names.json\")\n",
    "    if colab_json.exists():\n",
    "        with open(colab_json, 'r') as f:\n",
    "            colab_classes = json.load(f)\n",
    "\n",
    "colab_num_classes = len(colab_classes) if colab_classes else 38\n",
    "\n",
    "colab_model = timm.create_model('efficientnet_b4', pretrained=False, num_classes=colab_num_classes)\n",
    "colab_model.load_state_dict(colab_checkpoint['model_state_dict'])\n",
    "colab_model = colab_model.to(device)\n",
    "colab_model.eval()\n",
    "print(f\"   ‚úÖ Colab Model: {colab_num_classes} classes\")\n",
    "\n",
    "# Transform\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"‚úÖ BOTH MODELS LOADED!\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nüìä Local Model Classes ({local_num_classes}):\")\n",
    "for i, c in enumerate(local_classes[:10]):\n",
    "    print(f\"   {i+1}. {c}\")\n",
    "print(\"   ...\")\n",
    "\n",
    "print(f\"\\nüìä Colab Model Classes ({colab_num_classes}):\")\n",
    "for i, c in enumerate(colab_classes[:10]):\n",
    "    print(f\"   {i+1}. {c}\")\n",
    "print(\"   ...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d8530e2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Ensemble prediction function ready!\n",
      "\n",
      "üìù Usage: predict_single('path/to/image.jpg')\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# üéØ ENSEMBLE PREDICTION FUNCTION\n",
    "# ============================================\n",
    "\n",
    "def get_ensemble_features(image_path):\n",
    "    \"\"\"Get predictions from both models as features for Random Forest\"\"\"\n",
    "    \n",
    "    # Load and transform image\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    input_tensor = transform(image).unsqueeze(0).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # Local model predictions (probabilities)\n",
    "        local_output = local_model(input_tensor)\n",
    "        local_probs = torch.softmax(local_output, dim=1).cpu().numpy().flatten()\n",
    "        \n",
    "        # Colab model predictions (probabilities)\n",
    "        colab_output = colab_model(input_tensor)\n",
    "        colab_probs = torch.softmax(colab_output, dim=1).cpu().numpy().flatten()\n",
    "    \n",
    "    # Combine features: [local_probs (34), colab_probs (38), top predictions]\n",
    "    local_top = local_probs.max()\n",
    "    local_pred = local_probs.argmax()\n",
    "    colab_top = colab_probs.max()\n",
    "    colab_pred = colab_probs.argmax()\n",
    "    \n",
    "    # Feature vector\n",
    "    features = np.concatenate([\n",
    "        local_probs,           # 34 features\n",
    "        colab_probs,           # 38 features  \n",
    "        [local_top, colab_top, local_pred, colab_pred]  # 4 extra features\n",
    "    ])\n",
    "    \n",
    "    return features, local_pred, colab_pred, local_top, colab_top\n",
    "\n",
    "def predict_single(image_path):\n",
    "    \"\"\"Predict using both models and show results\"\"\"\n",
    "    features, local_pred, colab_pred, local_conf, colab_conf = get_ensemble_features(image_path)\n",
    "    \n",
    "    print(f\"\\nüì∑ Image: {Path(image_path).name}\")\n",
    "    print(\"-\"*50)\n",
    "    print(f\"üîµ Local Model:  {local_classes[local_pred]} ({local_conf*100:.1f}%)\")\n",
    "    print(f\"üü¢ Colab Model:  {colab_classes[colab_pred]} ({colab_conf*100:.1f}%)\")\n",
    "    \n",
    "    # Simple voting - higher confidence wins\n",
    "    if local_conf > colab_conf:\n",
    "        final = local_classes[local_pred]\n",
    "        final_conf = local_conf\n",
    "        source = \"Local\"\n",
    "    else:\n",
    "        final = colab_classes[colab_pred]\n",
    "        final_conf = colab_conf\n",
    "        source = \"Colab\"\n",
    "    \n",
    "    print(f\"üèÜ Final (Max Conf): {final} ({final_conf*100:.1f}%) - from {source}\")\n",
    "    \n",
    "    return features, final\n",
    "\n",
    "print(\"‚úÖ Ensemble prediction function ready!\")\n",
    "print(\"\\nüìù Usage: predict_single('path/to/image.jpg')\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "453dd33a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "üå≤ TRAINING RANDOM FOREST ENSEMBLE\n",
      "======================================================================\n",
      "\n",
      "üîÑ Extracting features from both models...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing classes: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 34/34 [02:16<00:00,  4.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Collected 680 samples from 34 classes\n",
      "üìä Feature shape: (680, 76)\n",
      "\n",
      "üìä Train: 544 samples\n",
      "üìä Test: 136 samples\n",
      "\n",
      "üå≤ Training Random Forest...\n",
      "\n",
      "======================================================================\n",
      "üéØ RANDOM FOREST ENSEMBLE RESULTS\n",
      "======================================================================\n",
      "\n",
      "üèÜ Ensemble Accuracy: 100.00%\n",
      "\n",
      "üìä Comparison:\n",
      "   Local Model (EfficientNet):  97.82%\n",
      "   Colab Model (EfficientNet):  99.26%\n",
      "   üå≤ Random Forest Ensemble:   100.00%\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# üå≤ TRAIN RANDOM FOREST ENSEMBLE\n",
    "# ============================================\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import os\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"üå≤ TRAINING RANDOM FOREST ENSEMBLE\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Collect data from test images\n",
    "DATA_DIR = Path(r\"D:\\kisaan madadgaar\\Plant-Disease-Detection\\data\\downloads\\PakistanCrops_Merged\")\n",
    "\n",
    "# Build features and labels\n",
    "print(\"\\nüîÑ Extracting features from both models...\")\n",
    "\n",
    "X_features = []\n",
    "y_labels = []\n",
    "all_class_names = []\n",
    "\n",
    "# Get all class folders\n",
    "class_folders = sorted([f for f in DATA_DIR.iterdir() if f.is_dir()])\n",
    "\n",
    "for class_idx, folder in enumerate(tqdm(class_folders, desc=\"Processing classes\")):\n",
    "    class_name = folder.name\n",
    "    all_class_names.append(class_name)\n",
    "    \n",
    "    # Get images (sample 20 per class for speed)\n",
    "    images = list(folder.glob('*.jpg')) + list(folder.glob('*.JPG')) + list(folder.glob('*.png'))\n",
    "    sample_images = images[:20]  # Take first 20\n",
    "    \n",
    "    for img_path in sample_images:\n",
    "        try:\n",
    "            features, _, _, _, _ = get_ensemble_features(str(img_path))\n",
    "            X_features.append(features)\n",
    "            y_labels.append(class_idx)\n",
    "        except Exception as e:\n",
    "            continue\n",
    "\n",
    "X_features = np.array(X_features)\n",
    "y_labels = np.array(y_labels)\n",
    "\n",
    "print(f\"\\n‚úÖ Collected {len(X_features)} samples from {len(all_class_names)} classes\")\n",
    "print(f\"üìä Feature shape: {X_features.shape}\")\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_features, y_labels, test_size=0.2, random_state=42, stratify=y_labels\n",
    ")\n",
    "\n",
    "print(f\"\\nüìä Train: {len(X_train)} samples\")\n",
    "print(f\"üìä Test: {len(X_test)} samples\")\n",
    "\n",
    "# Train Random Forest\n",
    "print(\"\\nüå≤ Training Random Forest...\")\n",
    "rf_model = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=20,\n",
    "    min_samples_split=5,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate\n",
    "y_pred = rf_model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f\"\\n\" + \"=\"*70)\n",
    "print(f\"üéØ RANDOM FOREST ENSEMBLE RESULTS\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nüèÜ Ensemble Accuracy: {accuracy*100:.2f}%\")\n",
    "print(f\"\\nüìä Comparison:\")\n",
    "print(f\"   Local Model (EfficientNet):  97.82%\")\n",
    "print(f\"   Colab Model (EfficientNet):  99.26%\")\n",
    "print(f\"   üå≤ Random Forest Ensemble:   {accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d9c81b81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "üíæ ENSEMBLE MODEL SAVED!\n",
      "======================================================================\n",
      "\n",
      "üìÅ Files saved:\n",
      "   ‚úÖ ensemble_rf_model.joblib (2530.6 KB)\n",
      "   ‚úÖ ensemble_info.json\n",
      "\n",
      "üéØ Final Ensemble Accuracy: 100.00%\n",
      "\n",
      "======================================================================\n",
      "üéâ ENSEMBLE COMPLETE!\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# üíæ SAVE ENSEMBLE MODEL\n",
    "# ============================================\n",
    "import joblib\n",
    "\n",
    "SAVE_DIR = Path(r\"D:\\kisaan madadgaar\\Plant-Disease-Detection\\saved_models\")\n",
    "\n",
    "# Save Random Forest model\n",
    "rf_path = SAVE_DIR / 'ensemble_rf_model.joblib'\n",
    "joblib.dump(rf_model, rf_path)\n",
    "\n",
    "# Save class names\n",
    "ensemble_info = {\n",
    "    'ensemble_accuracy': accuracy * 100,\n",
    "    'local_model_classes': local_classes,\n",
    "    'colab_model_classes': colab_classes,\n",
    "    'all_class_names': all_class_names,\n",
    "    'num_classes': len(all_class_names),\n",
    "    'feature_size': X_features.shape[1],\n",
    "    'train_samples': len(X_train),\n",
    "    'test_samples': len(X_test)\n",
    "}\n",
    "\n",
    "with open(SAVE_DIR / 'ensemble_info.json', 'w') as f:\n",
    "    json.dump(ensemble_info, f, indent=2)\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"üíæ ENSEMBLE MODEL SAVED!\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nüìÅ Files saved:\")\n",
    "print(f\"   ‚úÖ ensemble_rf_model.joblib ({rf_path.stat().st_size/1024:.1f} KB)\")\n",
    "print(f\"   ‚úÖ ensemble_info.json\")\n",
    "\n",
    "print(f\"\\nüéØ Final Ensemble Accuracy: {accuracy*100:.2f}%\")\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üéâ ENSEMBLE COMPLETE!\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2951b7c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# CELL 9: Plot Training History\n",
    "# ============================================\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "epochs_range = range(1, len(history['train_loss']) + 1)\n",
    "\n",
    "# Loss plot\n",
    "axes[0].plot(epochs_range, history['train_loss'], 'b-', label='Train Loss', linewidth=2, marker='o')\n",
    "axes[0].plot(epochs_range, history['val_loss'], 'r-', label='Val Loss', linewidth=2, marker='s')\n",
    "axes[0].set_xlabel('Epoch', fontsize=12)\n",
    "axes[0].set_ylabel('Loss', fontsize=12)\n",
    "axes[0].set_title('Training and Validation Loss', fontsize=14)\n",
    "axes[0].legend(fontsize=10)\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Accuracy plot\n",
    "axes[1].plot(epochs_range, history['train_acc'], 'b-', label='Train Accuracy', linewidth=2, marker='o')\n",
    "axes[1].plot(epochs_range, history['val_acc'], 'r-', label='Val Accuracy', linewidth=2, marker='s')\n",
    "axes[1].axhline(y=test_acc, color='g', linestyle='--', linewidth=2, label=f'Test Acc: {test_acc:.1f}%')\n",
    "axes[1].axhline(y=best_val_acc, color='orange', linestyle=':', linewidth=2, label=f'Best Val: {best_val_acc:.1f}%')\n",
    "axes[1].set_xlabel('Epoch', fontsize=12)\n",
    "axes[1].set_ylabel('Accuracy (%)', fontsize=12)\n",
    "axes[1].set_title('Training and Validation Accuracy', fontsize=14)\n",
    "axes[1].legend(fontsize=10)\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(SAVE_DIR / 'training_history.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\n‚úÖ Plot saved to: {SAVE_DIR / 'training_history.png'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7583e425",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# CELL 10: Save Final Model & Metadata\n",
    "# ============================================\n",
    "print(\"=\"*70)\n",
    "print(\"üíæ SAVING FINAL MODEL\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Save model info\n",
    "model_info = {\n",
    "    'class_names': class_names,\n",
    "    'num_classes': num_classes,\n",
    "    'test_accuracy': test_acc,\n",
    "    'best_val_accuracy': best_val_acc,\n",
    "    'model_architecture': 'efficientnet_b4',\n",
    "    'total_images': len(all_image_paths),\n",
    "    'epochs_trained': len(history['train_loss']),\n",
    "    'final_train_acc': history['train_acc'][-1],\n",
    "    'final_val_acc': history['val_acc'][-1],\n",
    "    'device': str(device)\n",
    "}\n",
    "\n",
    "with open(SAVE_DIR / 'model_info.json', 'w') as f:\n",
    "    json.dump(model_info, f, indent=2)\n",
    "\n",
    "with open(SAVE_DIR / 'training_history.json', 'w') as f:\n",
    "    json.dump(history, f, indent=2)\n",
    "\n",
    "# Copy to Flask app folder\n",
    "FLASK_DIR = Path(r\"D:\\kisaan madadgaar\\Plant-Disease-Detection\\Flask Deployed App\")\n",
    "if FLASK_DIR.exists():\n",
    "    import shutil\n",
    "    shutil.copy(SAVE_DIR / 'pakistan_model_best.pth', FLASK_DIR / 'pakistan_model_best.pth')\n",
    "    shutil.copy(SAVE_DIR / 'class_names.json', FLASK_DIR / 'class_names.json')\n",
    "    print(f\"\\nüìÅ Copied model files to Flask app folder!\")\n",
    "\n",
    "print(f\"\\nüíæ Files saved:\")\n",
    "print(f\"   ‚úÖ pakistan_model_best.pth (model weights)\")\n",
    "print(f\"   ‚úÖ class_names.json (class labels)\")\n",
    "print(f\"   ‚úÖ model_info.json (metadata)\")\n",
    "print(f\"   ‚úÖ training_history.json (training log)\")\n",
    "print(f\"   ‚úÖ training_history.png (plot)\")\n",
    "\n",
    "# File sizes\n",
    "model_size = (SAVE_DIR / 'pakistan_model_best.pth').stat().st_size / (1024*1024)\n",
    "print(f\"\\nüìä Model size: {model_size:.1f} MB\")\n",
    "\n",
    "print(f\"\\n\" + \"=\"*70)\n",
    "print(\"üéâ ALL DONE!\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nüìÅ Model saved to: {SAVE_DIR}\")\n",
    "print(f\"üéØ Test Accuracy: {test_acc:.2f}%\")\n",
    "print(f\"üèÜ Best Val Accuracy: {best_val_acc:.2f}%\")\n",
    "print(f\"\\nüöÄ Next: Run Flask app to test the model!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fb42e20",
   "metadata": {},
   "source": [
    "## ‚úÖ Training Complete!\n",
    "\n",
    "### üìÅ Saved Files:\n",
    "- `saved_models/pakistan_model_best.pth` - Model weights\n",
    "- `saved_models/class_names.json` - Class labels\n",
    "- `saved_models/model_info.json` - Metadata\n",
    "- `saved_models/training_history.png` - Training plot\n",
    "\n",
    "### üöÄ Next Steps:\n",
    "1. Model files automatically copied to `Flask Deployed App/` folder\n",
    "2. Run the Flask app: `python app.py`\n",
    "3. Test with images!\n",
    "\n",
    "### üáµüá∞ ⁄©ÿ≥ÿßŸÜ ŸÖÿØÿØ⁄Øÿßÿ± - Helping Pakistani Farmers with AI!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".conda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
